{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Exploratory Analysis\n",
    "Analysis = True\n",
    "\n",
    "#### Column Removal\n",
    "Remove_Cols_with_many_bad_data = True\n",
    "NaN_Zero_Threshold = 0.8\n",
    "\n",
    "#### Outliers\n",
    "RemoveOutliers = False    #Using IQR\n",
    "Times_IQR = 1.5           #Normal factor (1.5). Kills minority class if class included!!\n",
    "\n",
    "## Outliers by class\n",
    "RemoveOutliers_PositiveClass = False\n",
    "RemoveOutliers_NegativeClass = False  #It removes >90% of the class\n",
    "\n",
    "#### NaN and Zero replacement\n",
    "NaN_Zero_Replacement = True\n",
    "NaN_Zero_Replacement_Mode = 'general' #general or perClass\n",
    "NaN_Zero_Replacement_Operation = 'median' #median or mean\n",
    "NaN_Zero_Replacement_Sort = True\n",
    "\n",
    "#### Data Projections\n",
    "ProjectBins = True\n",
    "ProjectBin_Operation = \"mean\"  #sum or mean\n",
    "RemoveSubBins = True\n",
    "\n",
    "#### Rounding values\n",
    "Rounding = False     #Does not change the results and makes the process faster\n",
    "RoudingDecimals = 2\n",
    "\n",
    "#### Feature Selection\n",
    "RunCorrelationAnalysis = True   #Using Pearson Correlation\n",
    "Corr_FeatureSelection = 2   #0, 1, 2, 3, 4\n",
    "\n",
    "#### Resampling\n",
    "Upsampling = True                #Previous to Bagging\n",
    "UpsamplingAproach = 'ADASYN'    #ADASYN/SMOTE\n",
    "_sampling_strategy = 0.8                #'minority'/double\n",
    "\n",
    "#### Train-Test split\n",
    "EnableSplitting = True    #If False, no RF score and CM can be calculated\n",
    "_test_size = 0.2\n",
    "\n",
    "#### GridSearch\n",
    "GridSearch = False\n",
    "_cv = 5\n",
    "_verbose = 3\n",
    "## RF\n",
    "ParamGrid_RF = {'max_depth': [4,5,6,10,20], 'n_estimators':[100], \\\n",
    "                'class_weight':[{0:1,1:35},{1:35,0:1},'balanced'], \\\n",
    "                'verbose':[1], 'bootstrap': [True]};    # 'class_weight':[{0:1,1:35},{1:35,0:1}]\n",
    "## SVM\n",
    "SVM_Kernels = ['rbf','linear']    #['linear', 'rbf','sigmoid','poly']\n",
    "SVM_Cs = [0.1, 1, 10]\n",
    "SVM_gammas = [0.1, 1]\n",
    "ParamGrid_SVM = {'kernel': SVM_Kernels, 'C': SVM_Cs, 'gamma': SVM_gammas, 'verbose':[2]}\n",
    "\n",
    "#### Model to Use\n",
    "Multimode = False   # Not implemented\n",
    "ModelToUse = 'RF'  # RF,SVM\n",
    "\n",
    "#### Random Forest Parameters (ONLY WHEN GRIDSEARCH False)\n",
    "_max_depth = 5        #None (default)\n",
    "_n_estimators = 100\n",
    "_bootstrap = True\n",
    "_class_weight ='balanced'\n",
    "_SEED = 1\n",
    "_n_jobs = -1\n",
    "\n",
    "#### Support Vector Machine (ONLY WHEN GRIDSEARCH False)\n",
    "_C=10.0\n",
    "_kernel='sigmoid'       #'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'\n",
    "_degree=3               #3(default)\n",
    "_gamma='scale'\n",
    "_coef0=0.0\n",
    "_shrinking=True\n",
    "_probability=True\n",
    "_tol=0.001\n",
    "_cache_size=200\n",
    "_class_weight=None\n",
    "_verbose=True\n",
    "_max_iter=-1\n",
    "_decision_function_shape='ovr'\n",
    "_random_state=None\n",
    "\n",
    "#### Bagging\n",
    "Bagging = True\n",
    "# BC\n",
    "_n_bootstraps = 3\n",
    "_n_estimators = 10\n",
    "_max_samples = 1.0\n",
    "_max_features = 1.0\n",
    "_bootstrap = True\n",
    "_bootstrap_features = False\n",
    "_bootstrap = True\n",
    "_bootstrap_features = False\n",
    "_oob_score = False\n",
    "_warm_start = False\n",
    "_n_jobs = 4\n",
    "_random_state = None\n",
    "_verbose = 3\n",
    "\n",
    "#### Favor True Class (after prediction), not needed if SearchGreed (with scorer) True\n",
    "FavorTrueClass = False\n",
    "FavorThreshold = 0.45    #All False predictions between [0.5,FavorThreshold) are switched to True\n",
    "\n",
    "SaveToFile = True\n",
    "FileName = \"prediction_results_v6.csv\"\n",
    "\n",
    "#### Use existing model\n",
    "UseExistingModel = False\n",
    "modelFileName = \"model_v6_MAC.joblib\"\n",
    "if (UseExistingModel == True):\n",
    "    print(\"Using model from disk!!!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#import winsound\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import ADASYN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usefull functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ColumnFiltering1_ZerosNaNs_byThreshold(data,threshold):\n",
    "    \n",
    "    columnsNames = list(data.columns.values)\n",
    "    total_rows = train.shape[0]\n",
    "    thr = total_rows * threshold\n",
    "    \n",
    "    for i in columnsNames:\n",
    "        count = 0\n",
    "        \n",
    "        s = data[i]\n",
    "        if (i!= 'class'):\n",
    "            for j in s:\n",
    "                if math.isnan(j) or j == 0.0:\n",
    "                    count += 1\n",
    "            #print(i + \" \" + str(count))\n",
    "        if count >= thr:\n",
    "            data.drop(i, axis = 1, inplace = True)\n",
    "            #print (\"Droping \" + i)\n",
    "            \n",
    "def ClassTo01(data):\n",
    "    data[\"class\"].replace(to_replace = \"neg\", value = \"0\", inplace = True)\n",
    "    data[\"class\"].replace(to_replace = \"pos\", value = \"1\", inplace = True)\n",
    "    \n",
    "def PositiveData(data):\n",
    "    return data[(data[\"class\"] == 1)]\n",
    "    \n",
    "def NegativeData(data):\n",
    "    return data[(data[\"class\"] == 0)]\n",
    "\n",
    "def ReplaceNaNsForStats(data,strategy):\n",
    "    columnsNames = list(data.columns.values)\n",
    "    imp = Imputer(missing_values = \"NaN\", strategy = strategy, axis = 0, copy = False)\n",
    "    d = imp.fit_transform(data)\n",
    "    aux = pd.DataFrame(d, columns=columnsNames)\n",
    "    aux.index = data.index\n",
    "    return aux.copy()\n",
    "\n",
    "def NewColFromBin_v2(data,colName,op):\n",
    "    sum = 0\n",
    "    \n",
    "    if colName + '_000' in data.columns: sum += data[colName + '_000']\n",
    "    if colName + '_001' in data.columns: sum += data[colName + '_001']\n",
    "    if colName + '_002' in data.columns: sum += data[colName + '_002']\n",
    "    if colName + '_003' in data.columns: sum += data[colName + '_003']\n",
    "    if colName + '_004' in data.columns: sum += data[colName + '_004']\n",
    "    if colName + '_005' in data.columns: sum += data[colName + '_005']\n",
    "    if colName + '_006' in data.columns: sum += data[colName + '_006']\n",
    "    if colName + '_007' in data.columns: sum += data[colName + '_007']\n",
    "    if colName + '_008' in data.columns: sum += data[colName + '_008']\n",
    "    if colName + '_009' in data.columns: sum += data[colName + '_009']\n",
    "    \n",
    "    if (op == 'sum'): retorno = sum\n",
    "    if (op == 'mean'): retorno = sum/10\n",
    "\n",
    "    return retorno\n",
    "    \n",
    "def DropBins(data,binName):\n",
    "    if binName + '_000' in data.columns: data.drop(binName + '_000', axis = 1, inplace = True)\n",
    "    if binName + '_001' in data.columns: data.drop(binName + '_001', axis = 1, inplace = True)\n",
    "    if binName + '_002' in data.columns: data.drop(binName + '_002', axis = 1, inplace = True)\n",
    "    if binName + '_003' in data.columns: data.drop(binName + '_003', axis = 1, inplace = True)\n",
    "    if binName + '_004' in data.columns: data.drop(binName + '_004', axis = 1, inplace = True)\n",
    "    if binName + '_005' in data.columns: data.drop(binName + '_005', axis = 1, inplace = True)\n",
    "    if binName + '_006' in data.columns: data.drop(binName + '_006', axis = 1, inplace = True)\n",
    "    if binName + '_007' in data.columns: data.drop(binName + '_007', axis = 1, inplace = True)\n",
    "    if binName + '_008' in data.columns: data.drop(binName + '_008', axis = 1, inplace = True)\n",
    "    if binName + '_009' in data.columns: data.drop(binName + '_009', axis = 1, inplace = True)\n",
    "\n",
    "def FavorTrues(p):\n",
    "    if (p > FavorThreshold):\n",
    "        retorno = 'true'\n",
    "    else:\n",
    "        retorno = 'false'\n",
    "    return retorno\n",
    "\n",
    "def getCost(y_test,y_pred):\n",
    "    tn,fp,fn,tp = confusion_matrix(y_test,y_pred).ravel()\n",
    "    return (fp*100 + fn*3500)\n",
    "\n",
    "\n",
    "def Beep():\n",
    "    frequency = 2500  # Set Frequency To 2500 Hertz\n",
    "    duration = 1000  # Set Duration To 1000 ms == 1 second\n",
    "    winsound.Beep(frequency, duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Training and Test datasets\n",
    "train = pd.read_csv(\"aps_failure_train.csv\", na_values=\"na\")\n",
    "test = pd.read_csv(\"aps_failure_test.csv\", na_values=\"na\")\n",
    "#test = pd.read_csv(\"aps_failure_test_set.csv\", na_values=\"na\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Discovery\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    55968\n",
       "True      1032\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking class feature\n",
    "train[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57000 entries, 0 to 56999\n",
      "Columns: 171 entries, class to eg_000\n",
      "dtypes: bool(1), float64(169), int64(1)\n",
      "memory usage: 74.0 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Data types\n",
    "if(Analysis == True):\n",
    "    print(train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          count         mean          std  min      25%        50%        75%  \\\n",
      "aa_000  57000.0      61074.0     232734.0  0.0    872.0    30840.0    48942.0   \n",
      "ab_000  13046.0          1.0          3.0  0.0      0.0        0.0        0.0   \n",
      "ac_000  53781.0  354187065.0  793240902.0  0.0     16.0      152.0      966.0   \n",
      "ad_000  42725.0     201369.0   41530171.0  0.0     24.0      128.0      432.0   \n",
      "ae_000  54609.0          7.0        144.0  0.0      0.0        0.0        0.0   \n",
      "af_000  54609.0         11.0        196.0  0.0      0.0        0.0        0.0   \n",
      "ag_000  56328.0        224.0      20940.0  0.0      0.0        0.0        0.0   \n",
      "ag_001  56328.0       1106.0      35294.0  0.0      0.0        0.0        0.0   \n",
      "ag_002  56328.0       9526.0     161482.0  0.0      0.0        0.0        0.0   \n",
      "ag_003  56328.0      92700.0     759330.0  0.0      0.0        0.0        0.0   \n",
      "ag_004  56328.0     445606.0    2217632.0  0.0    310.0     3706.0    50974.0   \n",
      "ag_005  56328.0    1124752.0    3226828.0  0.0  13986.0   178836.0   923398.0   \n",
      "ag_006  56328.0    1665498.0    3895117.0  0.0  10804.0   937191.0  1889096.0   \n",
      "ag_007  56328.0     499825.0    1399681.0  0.0      0.0   118949.0   590420.0   \n",
      "ag_008  56328.0      36146.0     238897.0  0.0      0.0     1812.0    26796.0   \n",
      "ag_009  56328.0       5541.0     181772.0  0.0      0.0        0.0      370.0   \n",
      "ah_000  56365.0    1838969.0    4275079.0  0.0  30300.0  1005844.0  1605868.0   \n",
      "ai_000  56388.0       9932.0     178279.0  0.0      0.0        0.0        0.0   \n",
      "aj_000  56388.0       1024.0      45750.0  0.0      0.0        0.0        0.0   \n",
      "ak_000  52772.0        699.0      68537.0  0.0      0.0        0.0        0.0   \n",
      "al_000  56380.0      62301.0     583669.0  0.0      0.0        0.0     1246.0   \n",
      "am_0    56388.0      98225.0     911651.0  0.0      0.0        0.0     2410.0   \n",
      "an_000  56380.0    3513518.0    7957260.0  0.0  74428.0  1923403.0  3138693.0   \n",
      "ao_000  56418.0    3049226.0    6982559.0  0.0  66674.0  1650780.0  2688054.0   \n",
      "ap_000  56380.0    1020627.0    3128710.0  0.0  25414.0   357890.0   727115.0   \n",
      "aq_000  56418.0     450140.0    1282288.0  0.0   4228.0   178876.0   377737.0   \n",
      "ar_000  54374.0          0.0          5.0  0.0      0.0        0.0        0.0   \n",
      "as_000  56388.0        248.0      29421.0  0.0      0.0        0.0        0.0   \n",
      "at_000  56388.0       5272.0     122911.0  0.0      0.0        0.0        0.0   \n",
      "au_000  56388.0        334.0      29176.0  0.0      0.0        0.0        0.0   \n",
      "...         ...          ...          ...  ...      ...        ...        ...   \n",
      "dl_000  53143.0      28457.0    1106474.0  0.0      0.0        0.0        0.0   \n",
      "dm_000  53142.0       7816.0     282637.0  0.0      0.0        0.0        0.0   \n",
      "dn_000  56321.0      34317.0      98285.0  0.0    668.0    14376.0    27494.0   \n",
      "do_000  54374.0      28903.0      64251.0  0.0     20.0    10452.0    37750.0   \n",
      "dp_000  54372.0       7045.0      14596.0  0.0      6.0     2535.0     8304.0   \n",
      "dq_000  54372.0    4514995.0   96815439.0  0.0      0.0        0.0        0.0   \n",
      "dr_000  54372.0     206525.0    1377926.0  0.0      0.0        0.0        0.0   \n",
      "ds_000  54371.0      91199.0     214219.0  0.0    703.0    48372.0    99631.0   \n",
      "dt_000  54371.0      15639.0      34978.0  0.0    152.0     8358.0    17684.0   \n",
      "du_000  54372.0    4126072.0   11718849.0  0.0   5495.0   187100.0  3477845.0   \n",
      "dv_000  54372.0     609993.0    2192283.0  0.0    750.0    31082.0   532492.0   \n",
      "dx_000  54374.0     803517.0    4230006.0  0.0      0.0        0.0     9014.0   \n",
      "dy_000  54373.0       8057.0      61653.0  0.0      0.0        0.0       36.0   \n",
      "dz_000  54375.0          0.0         11.0  0.0      0.0        0.0        0.0   \n",
      "ea_000  54375.0          2.0         57.0  0.0      0.0        0.0        0.0   \n",
      "eb_000  53144.0   10165875.0   49205479.0  0.0      0.0   630290.0  4036320.0   \n",
      "ec_00   47274.0       1363.0       3534.0  0.0    115.0      763.0     1384.0   \n",
      "ed_000  47924.0       1469.0       3587.0  0.0     98.0      838.0     1514.0   \n",
      "ee_000  56326.0     746971.0    2445071.0  0.0  15957.0   261439.0   575616.0   \n",
      "ee_001  56326.0     790147.0    2522541.0  0.0   8660.0   348473.0   669391.0   \n",
      "ee_002  56326.0     448302.0    1118767.0  0.0   2988.0   235789.0   439176.0   \n",
      "ee_003  56326.0     212533.0     525716.0  0.0   1194.0   112710.0   218364.0   \n",
      "ee_004  56326.0     448590.0    1119554.0  0.0   2740.0   223874.0   466962.0   \n",
      "ee_005  56326.0     401979.0    1148645.0  0.0   3668.0   190717.0   403414.0   \n",
      "ee_006  56326.0     336230.0    1077579.0  0.0    528.0    93651.0   276558.0   \n",
      "ee_007  56326.0     345430.0    1642190.0  0.0    114.0    41540.0   168406.0   \n",
      "ee_008  56326.0     139282.0     465138.0  0.0      0.0     3934.0   139294.0   \n",
      "ee_009  56326.0       8376.0      50350.0  0.0      0.0        0.0     2000.0   \n",
      "ef_000  54374.0          0.0          4.0  0.0      0.0        0.0        0.0   \n",
      "eg_000  54375.0          0.0         11.0  0.0      0.0        0.0        0.0   \n",
      "\n",
      "                 max  \n",
      "aa_000  4.294967e+07  \n",
      "ab_000  2.040000e+02  \n",
      "ac_000  2.130707e+09  \n",
      "ad_000  8.584298e+09  \n",
      "ae_000  2.105000e+04  \n",
      "af_000  2.007000e+04  \n",
      "ag_000  3.376892e+06  \n",
      "ag_001  4.109372e+06  \n",
      "ag_002  1.055286e+07  \n",
      "ag_003  2.904730e+07  \n",
      "ag_004  5.396293e+07  \n",
      "ag_005  7.132792e+07  \n",
      "ag_006  7.691299e+07  \n",
      "ag_007  6.334675e+07  \n",
      "ag_008  1.770252e+07  \n",
      "ag_009  2.519851e+07  \n",
      "ah_000  7.424732e+07  \n",
      "ai_000  1.651285e+07  \n",
      "aj_000  5.629340e+06  \n",
      "ak_000  1.093059e+07  \n",
      "al_000  3.777930e+07  \n",
      "am_0    5.590351e+07  \n",
      "an_000  1.408618e+08  \n",
      "ao_000  1.222018e+08  \n",
      "ap_000  8.164520e+07  \n",
      "aq_000  2.556265e+07  \n",
      "ar_000  3.500000e+02  \n",
      "as_000  6.383704e+06  \n",
      "at_000  1.065435e+07  \n",
      "au_000  5.711474e+06  \n",
      "...              ...  \n",
      "dl_000  1.038581e+08  \n",
      "dm_000  2.369792e+07  \n",
      "dn_000  2.924584e+06  \n",
      "do_000  2.472198e+06  \n",
      "dp_000  5.353160e+05  \n",
      "dq_000  6.351873e+09  \n",
      "dr_000  5.013766e+07  \n",
      "ds_000  4.877996e+06  \n",
      "dt_000  8.552600e+05  \n",
      "du_000  3.517833e+08  \n",
      "dv_000  1.270345e+08  \n",
      "dx_000  1.142884e+08  \n",
      "dy_000  3.793022e+06  \n",
      "dz_000  1.414000e+03  \n",
      "ea_000  8.506000e+03  \n",
      "eb_000  4.496966e+09  \n",
      "ec_00   1.060200e+05  \n",
      "ed_000  8.838800e+04  \n",
      "ee_000  6.466015e+07  \n",
      "ee_001  8.043243e+07  \n",
      "ee_002  3.123272e+07  \n",
      "ee_003  1.454922e+07  \n",
      "ee_004  2.700915e+07  \n",
      "ee_005  5.743524e+07  \n",
      "ee_006  3.160781e+07  \n",
      "ee_007  5.324602e+07  \n",
      "ee_008  1.926740e+07  \n",
      "ee_009  4.570398e+06  \n",
      "ef_000  4.820000e+02  \n",
      "eg_000  1.720000e+03  \n",
      "\n",
      "[170 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "#Statistics\n",
    "if(Analysis == True):\n",
    "    stats = train.describe()\n",
    "    print(stats.round().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Outliers\n",
    "if(Analysis == True):\n",
    "    boxplot = train.boxplot()\n",
    "#train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if(Analysis == True):\n",
    "    positiveData = PositiveData(train)\n",
    "    negativeData = NegativeData(train)\n",
    "    boxplot = positiveData.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if(Analysis == True):\n",
    "    boxplot = negativeData.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleansing, data preparation, correlation analysis, feature selection, proyections, resampling..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = test.drop('class', axis=1)\n",
    "test['class'] = False\n",
    "\n",
    "ClassTo01(train)\n",
    "train[\"class\"] = pd.to_numeric(train[\"class\"])\n",
    "#ClassTo01(test)\n",
    "#test[\"class\"] = pd.to_numeric(test[\"class\"])\n",
    "#train.iloc[7:12,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    55968\n",
      "True      1032\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "if (RemoveOutliers == True): #Carefull, it kills minority class if class included!!\n",
    "    print(\"RemoveOutliers On\")\n",
    "    Q1 = train.quantile(0.25)\n",
    "    Q3 = train.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    rows = train['class'].count()\n",
    "    \n",
    "    train = train[~((train.loc[:, train.columns != 'class'] < (Q1 - Times_IQR * IQR))\\\n",
    "                    |(train.loc[:, train.columns != 'class'] > (Q3 + Times_IQR * IQR))).any(axis=1)]\n",
    "    rows_NoOutliers = train['class'].count()\n",
    "    \n",
    "    print(str(rows) + \"-\" + str(rows_NoOutliers) + \" = \" + str(rows-rows_NoOutliers))\n",
    "    train[\"class\"].value_counts()\n",
    "else:   \n",
    "    if (RemoveOutliers_PositiveClass == True or RemoveOutliers_NegativeClass == True):\n",
    "\n",
    "        rows = train['class'].count()\n",
    "        positiveData = PositiveData(train)\n",
    "        negativeData = NegativeData(train)\n",
    "\n",
    "        if (RemoveOutliers_PositiveClass == True):\n",
    "            print(\"RemoveOutliers_PositiveClass On\")\n",
    "            \n",
    "            Q1 = positiveData.quantile(0.25)\n",
    "            Q3 = positiveData.quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            positiveData = positiveData[~((positiveData < (Q1 - Times_IQR * IQR)) |(positiveData > (Q3 + Times_IQR * IQR))).any(axis=1)]\n",
    "\n",
    "        if (RemoveOutliers_NegativeClass == True):\n",
    "            print(\"RemoveOutliers_NegativeClass On\")\n",
    "            \n",
    "            Q1 = negativeData.quantile(0.25)\n",
    "            Q3 = negativeData.quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            negativeData = negativeData[~((negativeData < (Q1 - Times_IQR * IQR)) |(negativeData > (Q3 + Times_IQR * IQR))).any(axis=1)]\n",
    "\n",
    "        train = pd.concat([positiveData,negativeData])\n",
    "        train.sort_index(inplace=True)\n",
    "\n",
    "        rows_WithoutOutliers = train['class'].count()\n",
    "\n",
    "        print(str(rows) + \"-\" + str(rows_WithoutOutliers) + \" = \" + str(rows-rows_WithoutOutliers))\n",
    "print (train[\"class\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57000, 171)\n",
      "(19000, 171)\n",
      "Remove_Cols_with_many_bad_data On\n",
      "(57000, 129)\n",
      "(19000, 129)\n"
     ]
    }
   ],
   "source": [
    "if (Remove_Cols_with_many_bad_data == True):\n",
    "    print (train.shape)\n",
    "    print (test.shape)\n",
    "    print(\"Remove_Cols_with_many_bad_data On\")\n",
    "    ColumnFiltering1_ZerosNaNs_byThreshold(train,NaN_Zero_Threshold)\n",
    "    test = test[train.columns.values]\n",
    "\n",
    "print (train.shape)\n",
    "print (test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN_Zero_Replacement_Mode-General On\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(57000, 129)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if (NaN_Zero_Replacement):\n",
    "    if (NaN_Zero_Replacement_Mode == 'general'):\n",
    "        print(\"NaN_Zero_Replacement_Mode-General On\")\n",
    "        \n",
    "        train = ReplaceNaNsForStats(train,NaN_Zero_Replacement_Operation)\n",
    "        test = ReplaceNaNsForStats(test,NaN_Zero_Replacement_Operation)\n",
    "        \n",
    "    else: \n",
    "        if(NaN_Zero_Replacement_Mode == 'perClass'):\n",
    "            print(\"NaN_Zero_Replacement_Mode-PerClass On\")\n",
    "            \n",
    "            positiveData = PositiveData(train)\n",
    "            negativeData = NegativeData(train)\n",
    "            Data_P = ReplaceNaNsForStats(positiveData,NaN_Zero_Replacement_Operation)\n",
    "            Data_N = ReplaceNaNsForStats(negativeData,NaN_Zero_Replacement_Operation)\n",
    "            train = pd.concat([Data_P,Data_N])\n",
    "            if (NaN_Zero_Replacement_Sort == True): \n",
    "                train.sort_values('aa_000', axis=0, ascending=True, inplace=True)\n",
    "            test = ReplaceNaNsForStats(test,NaN_Zero_Replacement_Operation)\n",
    "\n",
    "\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProjectBins On\n",
      "RemoveSubBins On\n"
     ]
    }
   ],
   "source": [
    "if (ProjectBins == True):\n",
    "    print(\"ProjectBins On\")\n",
    "    #### Projecting bins into 7 new Features that summarize/average the bin's values.\n",
    "    train['ag'] = NewColFromBin_v2(train,'ag', ProjectBin_Operation)\n",
    "    train['ay'] = NewColFromBin_v2(train,'ay', ProjectBin_Operation)\n",
    "    train['az'] = NewColFromBin_v2(train,'az', ProjectBin_Operation)\n",
    "    train['ba'] = NewColFromBin_v2(train,'ba', ProjectBin_Operation)\n",
    "    train['cn'] = NewColFromBin_v2(train,'cn', ProjectBin_Operation)\n",
    "    train['cs'] = NewColFromBin_v2(train,'cs', ProjectBin_Operation)\n",
    "    train['ee'] = NewColFromBin_v2(train,'ee', ProjectBin_Operation)\n",
    "\n",
    "    test['ag'] = NewColFromBin_v2(test,'ag', ProjectBin_Operation)\n",
    "    test['ay'] = NewColFromBin_v2(test,'ay', ProjectBin_Operation)\n",
    "    test['az'] = NewColFromBin_v2(test,'az', ProjectBin_Operation)\n",
    "    test['ba'] = NewColFromBin_v2(test,'ba', ProjectBin_Operation)\n",
    "    test['cn'] = NewColFromBin_v2(test,'cn', ProjectBin_Operation)\n",
    "    test['cs'] = NewColFromBin_v2(test,'cs', ProjectBin_Operation)\n",
    "    test['ee'] = NewColFromBin_v2(test,'ee', ProjectBin_Operation)\n",
    "\n",
    "    \n",
    "if (RemoveSubBins == True):\n",
    "    print(\"RemoveSubBins On\")\n",
    "    # We are loosing the variance of the bins\n",
    "    # but we are simplifying the model by reducing the features\n",
    "    \n",
    "    # Removing splitted bins\n",
    "    DropBins(train,'ag')\n",
    "    DropBins(train,'ay')\n",
    "    DropBins(train,'az')\n",
    "    DropBins(train,'ba')\n",
    "    DropBins(train,'cn')\n",
    "    DropBins(train,'cs')\n",
    "    DropBins(train,'ee')\n",
    "    \n",
    "    DropBins(test,'ag')\n",
    "    DropBins(test,'ay')\n",
    "    DropBins(test,'az')\n",
    "    DropBins(test,'ba')\n",
    "    DropBins(test,'cn')\n",
    "    DropBins(test,'cs')\n",
    "    DropBins(test,'ee')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (Rounding == True):\n",
    "    print(\"Rounding On\")\n",
    "    train.round(RoudingDecimals)\n",
    "    test.round(RoudingDecimals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ah_000</th>\n",
       "      <th>aj_000</th>\n",
       "      <th>al_000</th>\n",
       "      <th>am_0</th>\n",
       "      <th>an_000</th>\n",
       "      <th>ao_000</th>\n",
       "      <th>...</th>\n",
       "      <th>eb_000</th>\n",
       "      <th>ec_00</th>\n",
       "      <th>ed_000</th>\n",
       "      <th>ag</th>\n",
       "      <th>ay</th>\n",
       "      <th>az</th>\n",
       "      <th>ba</th>\n",
       "      <th>cn</th>\n",
       "      <th>cs</th>\n",
       "      <th>ee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375922</td>\n",
       "      <td>-0.052777</td>\n",
       "      <td>-0.000567</td>\n",
       "      <td>0.525860</td>\n",
       "      <td>0.031937</td>\n",
       "      <td>0.374911</td>\n",
       "      <td>0.383793</td>\n",
       "      <td>0.526455</td>\n",
       "      <td>0.522661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156928</td>\n",
       "      <td>0.317041</td>\n",
       "      <td>0.358178</td>\n",
       "      <td>0.507917</td>\n",
       "      <td>0.485587</td>\n",
       "      <td>0.510470</td>\n",
       "      <td>0.511576</td>\n",
       "      <td>0.505155</td>\n",
       "      <td>0.511672</td>\n",
       "      <td>0.510547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aa_000</th>\n",
       "      <td>0.375922</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.043109</td>\n",
       "      <td>-0.001051</td>\n",
       "      <td>0.571282</td>\n",
       "      <td>0.037383</td>\n",
       "      <td>0.307326</td>\n",
       "      <td>0.310554</td>\n",
       "      <td>0.575253</td>\n",
       "      <td>0.578457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202855</td>\n",
       "      <td>0.378670</td>\n",
       "      <td>0.399766</td>\n",
       "      <td>0.554594</td>\n",
       "      <td>0.556873</td>\n",
       "      <td>0.555756</td>\n",
       "      <td>0.556104</td>\n",
       "      <td>0.553759</td>\n",
       "      <td>0.556079</td>\n",
       "      <td>0.555908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ac_000</th>\n",
       "      <td>-0.052777</td>\n",
       "      <td>-0.043109</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001804</td>\n",
       "      <td>-0.068221</td>\n",
       "      <td>-0.009492</td>\n",
       "      <td>-0.043101</td>\n",
       "      <td>-0.043575</td>\n",
       "      <td>-0.062477</td>\n",
       "      <td>-0.064169</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037743</td>\n",
       "      <td>-0.043352</td>\n",
       "      <td>-0.030470</td>\n",
       "      <td>-0.059616</td>\n",
       "      <td>-0.057979</td>\n",
       "      <td>-0.059176</td>\n",
       "      <td>-0.059913</td>\n",
       "      <td>-0.059328</td>\n",
       "      <td>-0.059876</td>\n",
       "      <td>-0.059683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ad_000</th>\n",
       "      <td>-0.000567</td>\n",
       "      <td>-0.001051</td>\n",
       "      <td>-0.001804</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001696</td>\n",
       "      <td>-0.000092</td>\n",
       "      <td>-0.000443</td>\n",
       "      <td>-0.000447</td>\n",
       "      <td>-0.001720</td>\n",
       "      <td>-0.001701</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000701</td>\n",
       "      <td>-0.001104</td>\n",
       "      <td>-0.001242</td>\n",
       "      <td>-0.001617</td>\n",
       "      <td>-0.001619</td>\n",
       "      <td>-0.001608</td>\n",
       "      <td>-0.001614</td>\n",
       "      <td>-0.001622</td>\n",
       "      <td>-0.001614</td>\n",
       "      <td>-0.001613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ah_000</th>\n",
       "      <td>0.525860</td>\n",
       "      <td>0.571282</td>\n",
       "      <td>-0.068221</td>\n",
       "      <td>-0.001696</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.081498</td>\n",
       "      <td>0.424205</td>\n",
       "      <td>0.429136</td>\n",
       "      <td>0.986293</td>\n",
       "      <td>0.971470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.358280</td>\n",
       "      <td>0.586838</td>\n",
       "      <td>0.611684</td>\n",
       "      <td>0.810358</td>\n",
       "      <td>0.797224</td>\n",
       "      <td>0.809388</td>\n",
       "      <td>0.809847</td>\n",
       "      <td>0.810432</td>\n",
       "      <td>0.809757</td>\n",
       "      <td>0.809519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aj_000</th>\n",
       "      <td>0.031937</td>\n",
       "      <td>0.037383</td>\n",
       "      <td>-0.009492</td>\n",
       "      <td>-0.000092</td>\n",
       "      <td>0.081498</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007575</td>\n",
       "      <td>0.007588</td>\n",
       "      <td>0.084285</td>\n",
       "      <td>0.068907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036010</td>\n",
       "      <td>0.081259</td>\n",
       "      <td>0.093644</td>\n",
       "      <td>0.112506</td>\n",
       "      <td>0.114615</td>\n",
       "      <td>0.112121</td>\n",
       "      <td>0.112029</td>\n",
       "      <td>0.113114</td>\n",
       "      <td>0.112049</td>\n",
       "      <td>0.112120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>al_000</th>\n",
       "      <td>0.374911</td>\n",
       "      <td>0.307326</td>\n",
       "      <td>-0.043101</td>\n",
       "      <td>-0.000443</td>\n",
       "      <td>0.424205</td>\n",
       "      <td>0.007575</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989366</td>\n",
       "      <td>0.423010</td>\n",
       "      <td>0.483840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083261</td>\n",
       "      <td>0.230923</td>\n",
       "      <td>0.217342</td>\n",
       "      <td>0.336365</td>\n",
       "      <td>0.348201</td>\n",
       "      <td>0.341279</td>\n",
       "      <td>0.343109</td>\n",
       "      <td>0.331530</td>\n",
       "      <td>0.343162</td>\n",
       "      <td>0.341435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_0</th>\n",
       "      <td>0.383793</td>\n",
       "      <td>0.310554</td>\n",
       "      <td>-0.043575</td>\n",
       "      <td>-0.000447</td>\n",
       "      <td>0.429136</td>\n",
       "      <td>0.007588</td>\n",
       "      <td>0.989366</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.424572</td>\n",
       "      <td>0.486244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076967</td>\n",
       "      <td>0.236797</td>\n",
       "      <td>0.220481</td>\n",
       "      <td>0.345878</td>\n",
       "      <td>0.357369</td>\n",
       "      <td>0.351221</td>\n",
       "      <td>0.352831</td>\n",
       "      <td>0.340861</td>\n",
       "      <td>0.352881</td>\n",
       "      <td>0.351370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>an_000</th>\n",
       "      <td>0.526455</td>\n",
       "      <td>0.575253</td>\n",
       "      <td>-0.062477</td>\n",
       "      <td>-0.001720</td>\n",
       "      <td>0.986293</td>\n",
       "      <td>0.084285</td>\n",
       "      <td>0.423010</td>\n",
       "      <td>0.424572</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328441</td>\n",
       "      <td>0.588406</td>\n",
       "      <td>0.611743</td>\n",
       "      <td>0.819938</td>\n",
       "      <td>0.807101</td>\n",
       "      <td>0.818687</td>\n",
       "      <td>0.819396</td>\n",
       "      <td>0.820002</td>\n",
       "      <td>0.819306</td>\n",
       "      <td>0.818805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ao_000</th>\n",
       "      <td>0.522661</td>\n",
       "      <td>0.578457</td>\n",
       "      <td>-0.064169</td>\n",
       "      <td>-0.001701</td>\n",
       "      <td>0.971470</td>\n",
       "      <td>0.068907</td>\n",
       "      <td>0.483840</td>\n",
       "      <td>0.486244</td>\n",
       "      <td>0.989841</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.322859</td>\n",
       "      <td>0.573606</td>\n",
       "      <td>0.593201</td>\n",
       "      <td>0.803068</td>\n",
       "      <td>0.794086</td>\n",
       "      <td>0.802303</td>\n",
       "      <td>0.803215</td>\n",
       "      <td>0.802571</td>\n",
       "      <td>0.803134</td>\n",
       "      <td>0.802434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ap_000</th>\n",
       "      <td>0.520655</td>\n",
       "      <td>0.516148</td>\n",
       "      <td>-0.065807</td>\n",
       "      <td>-0.001093</td>\n",
       "      <td>0.890870</td>\n",
       "      <td>0.095460</td>\n",
       "      <td>0.486568</td>\n",
       "      <td>0.507278</td>\n",
       "      <td>0.879295</td>\n",
       "      <td>0.845373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244320</td>\n",
       "      <td>0.571326</td>\n",
       "      <td>0.578484</td>\n",
       "      <td>0.769171</td>\n",
       "      <td>0.756758</td>\n",
       "      <td>0.769056</td>\n",
       "      <td>0.769580</td>\n",
       "      <td>0.768547</td>\n",
       "      <td>0.769503</td>\n",
       "      <td>0.769196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aq_000</th>\n",
       "      <td>0.533687</td>\n",
       "      <td>0.489701</td>\n",
       "      <td>-0.049912</td>\n",
       "      <td>-0.001421</td>\n",
       "      <td>0.895490</td>\n",
       "      <td>0.103937</td>\n",
       "      <td>0.350945</td>\n",
       "      <td>0.372881</td>\n",
       "      <td>0.868907</td>\n",
       "      <td>0.818655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265829</td>\n",
       "      <td>0.534388</td>\n",
       "      <td>0.560887</td>\n",
       "      <td>0.779581</td>\n",
       "      <td>0.756226</td>\n",
       "      <td>0.779027</td>\n",
       "      <td>0.779201</td>\n",
       "      <td>0.780112</td>\n",
       "      <td>0.779104</td>\n",
       "      <td>0.779118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>av_000</th>\n",
       "      <td>0.123983</td>\n",
       "      <td>0.082758</td>\n",
       "      <td>0.015243</td>\n",
       "      <td>-0.000577</td>\n",
       "      <td>0.183375</td>\n",
       "      <td>-0.001185</td>\n",
       "      <td>0.071475</td>\n",
       "      <td>0.069646</td>\n",
       "      <td>0.171824</td>\n",
       "      <td>0.162682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119929</td>\n",
       "      <td>0.149503</td>\n",
       "      <td>0.160584</td>\n",
       "      <td>0.197286</td>\n",
       "      <td>0.178445</td>\n",
       "      <td>0.197942</td>\n",
       "      <td>0.197626</td>\n",
       "      <td>0.197253</td>\n",
       "      <td>0.197675</td>\n",
       "      <td>0.197858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ax_000</th>\n",
       "      <td>0.108468</td>\n",
       "      <td>0.125917</td>\n",
       "      <td>-0.006992</td>\n",
       "      <td>-0.000877</td>\n",
       "      <td>0.229273</td>\n",
       "      <td>-0.003095</td>\n",
       "      <td>0.127473</td>\n",
       "      <td>0.122385</td>\n",
       "      <td>0.222783</td>\n",
       "      <td>0.222735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159275</td>\n",
       "      <td>0.187368</td>\n",
       "      <td>0.200991</td>\n",
       "      <td>0.216158</td>\n",
       "      <td>0.208828</td>\n",
       "      <td>0.216996</td>\n",
       "      <td>0.216792</td>\n",
       "      <td>0.215482</td>\n",
       "      <td>0.216849</td>\n",
       "      <td>0.217042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bb_000</th>\n",
       "      <td>0.545215</td>\n",
       "      <td>0.574745</td>\n",
       "      <td>-0.065497</td>\n",
       "      <td>-0.001564</td>\n",
       "      <td>0.983440</td>\n",
       "      <td>0.087826</td>\n",
       "      <td>0.492423</td>\n",
       "      <td>0.502012</td>\n",
       "      <td>0.985959</td>\n",
       "      <td>0.974705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.309016</td>\n",
       "      <td>0.596115</td>\n",
       "      <td>0.613726</td>\n",
       "      <td>0.823592</td>\n",
       "      <td>0.812097</td>\n",
       "      <td>0.823060</td>\n",
       "      <td>0.823819</td>\n",
       "      <td>0.823152</td>\n",
       "      <td>0.823736</td>\n",
       "      <td>0.823198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bc_000</th>\n",
       "      <td>0.172855</td>\n",
       "      <td>0.180224</td>\n",
       "      <td>-0.021158</td>\n",
       "      <td>-0.000543</td>\n",
       "      <td>0.281033</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.177739</td>\n",
       "      <td>0.165891</td>\n",
       "      <td>0.272160</td>\n",
       "      <td>0.284712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224643</td>\n",
       "      <td>0.201521</td>\n",
       "      <td>0.213167</td>\n",
       "      <td>0.218568</td>\n",
       "      <td>0.218976</td>\n",
       "      <td>0.218871</td>\n",
       "      <td>0.218839</td>\n",
       "      <td>0.217287</td>\n",
       "      <td>0.218884</td>\n",
       "      <td>0.219047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bd_000</th>\n",
       "      <td>0.169845</td>\n",
       "      <td>0.215008</td>\n",
       "      <td>-0.016913</td>\n",
       "      <td>-0.000529</td>\n",
       "      <td>0.333786</td>\n",
       "      <td>0.011243</td>\n",
       "      <td>0.194446</td>\n",
       "      <td>0.181540</td>\n",
       "      <td>0.318465</td>\n",
       "      <td>0.329595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.271407</td>\n",
       "      <td>0.246407</td>\n",
       "      <td>0.256945</td>\n",
       "      <td>0.260631</td>\n",
       "      <td>0.262987</td>\n",
       "      <td>0.260906</td>\n",
       "      <td>0.260776</td>\n",
       "      <td>0.259469</td>\n",
       "      <td>0.260835</td>\n",
       "      <td>0.261041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be_000</th>\n",
       "      <td>0.117382</td>\n",
       "      <td>0.182129</td>\n",
       "      <td>-0.024964</td>\n",
       "      <td>-0.000570</td>\n",
       "      <td>0.278491</td>\n",
       "      <td>0.004011</td>\n",
       "      <td>0.216537</td>\n",
       "      <td>0.205226</td>\n",
       "      <td>0.267735</td>\n",
       "      <td>0.280333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182078</td>\n",
       "      <td>0.239049</td>\n",
       "      <td>0.225222</td>\n",
       "      <td>0.219668</td>\n",
       "      <td>0.222318</td>\n",
       "      <td>0.219578</td>\n",
       "      <td>0.219452</td>\n",
       "      <td>0.218185</td>\n",
       "      <td>0.219501</td>\n",
       "      <td>0.219668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bf_000</th>\n",
       "      <td>0.195165</td>\n",
       "      <td>0.174637</td>\n",
       "      <td>-0.045399</td>\n",
       "      <td>-0.000560</td>\n",
       "      <td>0.312571</td>\n",
       "      <td>0.074014</td>\n",
       "      <td>0.093196</td>\n",
       "      <td>0.089026</td>\n",
       "      <td>0.288052</td>\n",
       "      <td>0.270706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185795</td>\n",
       "      <td>0.221827</td>\n",
       "      <td>0.247134</td>\n",
       "      <td>0.318695</td>\n",
       "      <td>0.321939</td>\n",
       "      <td>0.318154</td>\n",
       "      <td>0.317821</td>\n",
       "      <td>0.318754</td>\n",
       "      <td>0.317885</td>\n",
       "      <td>0.318117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bg_000</th>\n",
       "      <td>0.525225</td>\n",
       "      <td>0.571234</td>\n",
       "      <td>-0.068399</td>\n",
       "      <td>-0.001698</td>\n",
       "      <td>0.998298</td>\n",
       "      <td>0.081486</td>\n",
       "      <td>0.425041</td>\n",
       "      <td>0.427158</td>\n",
       "      <td>0.988065</td>\n",
       "      <td>0.971138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.358304</td>\n",
       "      <td>0.586122</td>\n",
       "      <td>0.611498</td>\n",
       "      <td>0.810027</td>\n",
       "      <td>0.796291</td>\n",
       "      <td>0.808930</td>\n",
       "      <td>0.809386</td>\n",
       "      <td>0.810154</td>\n",
       "      <td>0.809296</td>\n",
       "      <td>0.809058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bh_000</th>\n",
       "      <td>0.503051</td>\n",
       "      <td>0.526941</td>\n",
       "      <td>-0.066424</td>\n",
       "      <td>-0.001513</td>\n",
       "      <td>0.951452</td>\n",
       "      <td>0.108889</td>\n",
       "      <td>0.367291</td>\n",
       "      <td>0.375571</td>\n",
       "      <td>0.933295</td>\n",
       "      <td>0.893043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.307766</td>\n",
       "      <td>0.572159</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>0.802951</td>\n",
       "      <td>0.789357</td>\n",
       "      <td>0.801518</td>\n",
       "      <td>0.802085</td>\n",
       "      <td>0.803462</td>\n",
       "      <td>0.801961</td>\n",
       "      <td>0.801651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bi_000</th>\n",
       "      <td>0.436908</td>\n",
       "      <td>0.505887</td>\n",
       "      <td>-0.062591</td>\n",
       "      <td>-0.000926</td>\n",
       "      <td>0.831355</td>\n",
       "      <td>0.059669</td>\n",
       "      <td>0.425022</td>\n",
       "      <td>0.441020</td>\n",
       "      <td>0.828154</td>\n",
       "      <td>0.817755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270414</td>\n",
       "      <td>0.572995</td>\n",
       "      <td>0.568583</td>\n",
       "      <td>0.702338</td>\n",
       "      <td>0.691553</td>\n",
       "      <td>0.701440</td>\n",
       "      <td>0.702010</td>\n",
       "      <td>0.701977</td>\n",
       "      <td>0.701992</td>\n",
       "      <td>0.701581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bj_000</th>\n",
       "      <td>0.528382</td>\n",
       "      <td>0.463157</td>\n",
       "      <td>-0.060836</td>\n",
       "      <td>-0.001095</td>\n",
       "      <td>0.830864</td>\n",
       "      <td>0.112002</td>\n",
       "      <td>0.474717</td>\n",
       "      <td>0.505012</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.772423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193726</td>\n",
       "      <td>0.496983</td>\n",
       "      <td>0.512613</td>\n",
       "      <td>0.733674</td>\n",
       "      <td>0.721781</td>\n",
       "      <td>0.734449</td>\n",
       "      <td>0.734869</td>\n",
       "      <td>0.732784</td>\n",
       "      <td>0.734756</td>\n",
       "      <td>0.734570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bk_000</th>\n",
       "      <td>0.082218</td>\n",
       "      <td>0.026487</td>\n",
       "      <td>-0.085762</td>\n",
       "      <td>-0.000869</td>\n",
       "      <td>0.049506</td>\n",
       "      <td>0.010934</td>\n",
       "      <td>0.048622</td>\n",
       "      <td>0.054447</td>\n",
       "      <td>0.039278</td>\n",
       "      <td>0.027390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006258</td>\n",
       "      <td>0.059059</td>\n",
       "      <td>0.057238</td>\n",
       "      <td>0.051050</td>\n",
       "      <td>0.049240</td>\n",
       "      <td>0.051419</td>\n",
       "      <td>0.051361</td>\n",
       "      <td>0.050656</td>\n",
       "      <td>0.051403</td>\n",
       "      <td>0.051311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bl_000</th>\n",
       "      <td>0.046720</td>\n",
       "      <td>0.004669</td>\n",
       "      <td>-0.100134</td>\n",
       "      <td>-0.000937</td>\n",
       "      <td>0.014154</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.028095</td>\n",
       "      <td>0.032712</td>\n",
       "      <td>0.004283</td>\n",
       "      <td>-0.005073</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000585</td>\n",
       "      <td>0.033319</td>\n",
       "      <td>0.030201</td>\n",
       "      <td>0.017608</td>\n",
       "      <td>0.016031</td>\n",
       "      <td>0.017917</td>\n",
       "      <td>0.017769</td>\n",
       "      <td>0.017324</td>\n",
       "      <td>0.017819</td>\n",
       "      <td>0.017745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bm_000</th>\n",
       "      <td>0.031078</td>\n",
       "      <td>-0.007438</td>\n",
       "      <td>-0.103675</td>\n",
       "      <td>-0.000921</td>\n",
       "      <td>-0.005769</td>\n",
       "      <td>0.008548</td>\n",
       "      <td>0.019144</td>\n",
       "      <td>0.023412</td>\n",
       "      <td>-0.015348</td>\n",
       "      <td>-0.023104</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002563</td>\n",
       "      <td>0.016896</td>\n",
       "      <td>0.012994</td>\n",
       "      <td>-0.000203</td>\n",
       "      <td>-0.001174</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>-0.000488</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bn_000</th>\n",
       "      <td>0.020355</td>\n",
       "      <td>-0.014676</td>\n",
       "      <td>-0.105791</td>\n",
       "      <td>-0.000919</td>\n",
       "      <td>-0.018392</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>0.010118</td>\n",
       "      <td>0.014294</td>\n",
       "      <td>-0.027948</td>\n",
       "      <td>-0.034500</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006918</td>\n",
       "      <td>0.002534</td>\n",
       "      <td>-0.002283</td>\n",
       "      <td>-0.011678</td>\n",
       "      <td>-0.012611</td>\n",
       "      <td>-0.011286</td>\n",
       "      <td>-0.011540</td>\n",
       "      <td>-0.011889</td>\n",
       "      <td>-0.011514</td>\n",
       "      <td>-0.011500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bo_000</th>\n",
       "      <td>0.011050</td>\n",
       "      <td>-0.021640</td>\n",
       "      <td>-0.102492</td>\n",
       "      <td>-0.000895</td>\n",
       "      <td>-0.030554</td>\n",
       "      <td>0.004378</td>\n",
       "      <td>0.003431</td>\n",
       "      <td>0.007476</td>\n",
       "      <td>-0.040226</td>\n",
       "      <td>-0.046283</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008453</td>\n",
       "      <td>-0.005926</td>\n",
       "      <td>-0.011131</td>\n",
       "      <td>-0.023398</td>\n",
       "      <td>-0.024015</td>\n",
       "      <td>-0.023039</td>\n",
       "      <td>-0.023277</td>\n",
       "      <td>-0.023605</td>\n",
       "      <td>-0.023253</td>\n",
       "      <td>-0.023257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bs_000</th>\n",
       "      <td>0.200253</td>\n",
       "      <td>0.179588</td>\n",
       "      <td>-0.009803</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.314344</td>\n",
       "      <td>0.030994</td>\n",
       "      <td>0.130473</td>\n",
       "      <td>0.136849</td>\n",
       "      <td>0.306732</td>\n",
       "      <td>0.286912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121883</td>\n",
       "      <td>0.222646</td>\n",
       "      <td>0.238587</td>\n",
       "      <td>0.298274</td>\n",
       "      <td>0.295110</td>\n",
       "      <td>0.297957</td>\n",
       "      <td>0.297847</td>\n",
       "      <td>0.298447</td>\n",
       "      <td>0.297881</td>\n",
       "      <td>0.297815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bt_000</th>\n",
       "      <td>0.374552</td>\n",
       "      <td>0.999710</td>\n",
       "      <td>-0.043014</td>\n",
       "      <td>-0.001052</td>\n",
       "      <td>0.571495</td>\n",
       "      <td>0.037394</td>\n",
       "      <td>0.307419</td>\n",
       "      <td>0.310642</td>\n",
       "      <td>0.575469</td>\n",
       "      <td>0.578673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202954</td>\n",
       "      <td>0.378895</td>\n",
       "      <td>0.399955</td>\n",
       "      <td>0.554383</td>\n",
       "      <td>0.556616</td>\n",
       "      <td>0.555520</td>\n",
       "      <td>0.555888</td>\n",
       "      <td>0.553562</td>\n",
       "      <td>0.555863</td>\n",
       "      <td>0.555679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ct_000</th>\n",
       "      <td>0.029529</td>\n",
       "      <td>0.033470</td>\n",
       "      <td>0.023714</td>\n",
       "      <td>-0.000338</td>\n",
       "      <td>0.085691</td>\n",
       "      <td>0.009307</td>\n",
       "      <td>0.024661</td>\n",
       "      <td>0.026067</td>\n",
       "      <td>0.077703</td>\n",
       "      <td>0.068370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044892</td>\n",
       "      <td>0.088157</td>\n",
       "      <td>0.091718</td>\n",
       "      <td>0.124225</td>\n",
       "      <td>0.119506</td>\n",
       "      <td>0.124124</td>\n",
       "      <td>0.124014</td>\n",
       "      <td>0.124588</td>\n",
       "      <td>0.124044</td>\n",
       "      <td>0.124064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cu_000</th>\n",
       "      <td>0.071859</td>\n",
       "      <td>0.084755</td>\n",
       "      <td>-0.010076</td>\n",
       "      <td>-0.000477</td>\n",
       "      <td>0.161100</td>\n",
       "      <td>0.016532</td>\n",
       "      <td>0.096781</td>\n",
       "      <td>0.101437</td>\n",
       "      <td>0.154404</td>\n",
       "      <td>0.151876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080263</td>\n",
       "      <td>0.139195</td>\n",
       "      <td>0.135868</td>\n",
       "      <td>0.224859</td>\n",
       "      <td>0.230281</td>\n",
       "      <td>0.225315</td>\n",
       "      <td>0.225370</td>\n",
       "      <td>0.224703</td>\n",
       "      <td>0.225418</td>\n",
       "      <td>0.225317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv_000</th>\n",
       "      <td>0.224582</td>\n",
       "      <td>0.300415</td>\n",
       "      <td>0.017357</td>\n",
       "      <td>-0.002097</td>\n",
       "      <td>0.455983</td>\n",
       "      <td>0.009709</td>\n",
       "      <td>0.320119</td>\n",
       "      <td>0.321431</td>\n",
       "      <td>0.458054</td>\n",
       "      <td>0.477810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234826</td>\n",
       "      <td>0.376461</td>\n",
       "      <td>0.362734</td>\n",
       "      <td>0.411446</td>\n",
       "      <td>0.423082</td>\n",
       "      <td>0.412267</td>\n",
       "      <td>0.412487</td>\n",
       "      <td>0.409412</td>\n",
       "      <td>0.412569</td>\n",
       "      <td>0.412260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cx_000</th>\n",
       "      <td>0.194742</td>\n",
       "      <td>0.269579</td>\n",
       "      <td>-0.025294</td>\n",
       "      <td>-0.000690</td>\n",
       "      <td>0.377566</td>\n",
       "      <td>0.002013</td>\n",
       "      <td>0.352167</td>\n",
       "      <td>0.349544</td>\n",
       "      <td>0.381393</td>\n",
       "      <td>0.409986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193384</td>\n",
       "      <td>0.306795</td>\n",
       "      <td>0.281128</td>\n",
       "      <td>0.329950</td>\n",
       "      <td>0.339992</td>\n",
       "      <td>0.331126</td>\n",
       "      <td>0.331454</td>\n",
       "      <td>0.327325</td>\n",
       "      <td>0.331523</td>\n",
       "      <td>0.331297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cz_000</th>\n",
       "      <td>0.022330</td>\n",
       "      <td>0.045113</td>\n",
       "      <td>0.004219</td>\n",
       "      <td>-0.000262</td>\n",
       "      <td>0.106592</td>\n",
       "      <td>0.017296</td>\n",
       "      <td>0.018509</td>\n",
       "      <td>0.019382</td>\n",
       "      <td>0.097020</td>\n",
       "      <td>0.089299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066693</td>\n",
       "      <td>0.095203</td>\n",
       "      <td>0.092754</td>\n",
       "      <td>0.175403</td>\n",
       "      <td>0.177164</td>\n",
       "      <td>0.174770</td>\n",
       "      <td>0.174593</td>\n",
       "      <td>0.176317</td>\n",
       "      <td>0.174629</td>\n",
       "      <td>0.174753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>db_000</th>\n",
       "      <td>-0.017649</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>0.043201</td>\n",
       "      <td>-0.000685</td>\n",
       "      <td>-0.003752</td>\n",
       "      <td>0.006277</td>\n",
       "      <td>-0.011249</td>\n",
       "      <td>-0.011277</td>\n",
       "      <td>-0.000726</td>\n",
       "      <td>-0.001470</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008087</td>\n",
       "      <td>0.036320</td>\n",
       "      <td>0.036455</td>\n",
       "      <td>0.024224</td>\n",
       "      <td>0.025851</td>\n",
       "      <td>0.024255</td>\n",
       "      <td>0.023978</td>\n",
       "      <td>0.023750</td>\n",
       "      <td>0.023999</td>\n",
       "      <td>0.024093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dc_000</th>\n",
       "      <td>0.232068</td>\n",
       "      <td>0.308042</td>\n",
       "      <td>0.002190</td>\n",
       "      <td>-0.002255</td>\n",
       "      <td>0.480839</td>\n",
       "      <td>0.022018</td>\n",
       "      <td>0.309027</td>\n",
       "      <td>0.310857</td>\n",
       "      <td>0.479778</td>\n",
       "      <td>0.494328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247672</td>\n",
       "      <td>0.396900</td>\n",
       "      <td>0.382758</td>\n",
       "      <td>0.457684</td>\n",
       "      <td>0.468830</td>\n",
       "      <td>0.458321</td>\n",
       "      <td>0.458496</td>\n",
       "      <td>0.456015</td>\n",
       "      <td>0.458576</td>\n",
       "      <td>0.458342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dd_000</th>\n",
       "      <td>0.288221</td>\n",
       "      <td>0.289924</td>\n",
       "      <td>-0.040591</td>\n",
       "      <td>-0.001145</td>\n",
       "      <td>0.543936</td>\n",
       "      <td>0.033206</td>\n",
       "      <td>0.234301</td>\n",
       "      <td>0.228353</td>\n",
       "      <td>0.524810</td>\n",
       "      <td>0.509742</td>\n",
       "      <td>...</td>\n",
       "      <td>0.315521</td>\n",
       "      <td>0.416890</td>\n",
       "      <td>0.441382</td>\n",
       "      <td>0.489777</td>\n",
       "      <td>0.483869</td>\n",
       "      <td>0.489524</td>\n",
       "      <td>0.489100</td>\n",
       "      <td>0.489190</td>\n",
       "      <td>0.489201</td>\n",
       "      <td>0.489555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de_000</th>\n",
       "      <td>0.189567</td>\n",
       "      <td>0.155671</td>\n",
       "      <td>-0.014787</td>\n",
       "      <td>-0.000569</td>\n",
       "      <td>0.266978</td>\n",
       "      <td>0.008364</td>\n",
       "      <td>0.131669</td>\n",
       "      <td>0.126327</td>\n",
       "      <td>0.252747</td>\n",
       "      <td>0.249474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247906</td>\n",
       "      <td>0.193569</td>\n",
       "      <td>0.213306</td>\n",
       "      <td>0.203269</td>\n",
       "      <td>0.207763</td>\n",
       "      <td>0.203894</td>\n",
       "      <td>0.203763</td>\n",
       "      <td>0.202329</td>\n",
       "      <td>0.203809</td>\n",
       "      <td>0.203977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dn_000</th>\n",
       "      <td>0.501021</td>\n",
       "      <td>0.491353</td>\n",
       "      <td>-0.056030</td>\n",
       "      <td>-0.001364</td>\n",
       "      <td>0.901856</td>\n",
       "      <td>0.140100</td>\n",
       "      <td>0.399615</td>\n",
       "      <td>0.408378</td>\n",
       "      <td>0.865021</td>\n",
       "      <td>0.817948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289308</td>\n",
       "      <td>0.550363</td>\n",
       "      <td>0.577042</td>\n",
       "      <td>0.772783</td>\n",
       "      <td>0.757056</td>\n",
       "      <td>0.771846</td>\n",
       "      <td>0.772281</td>\n",
       "      <td>0.773348</td>\n",
       "      <td>0.772206</td>\n",
       "      <td>0.771981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>do_000</th>\n",
       "      <td>0.285458</td>\n",
       "      <td>0.299866</td>\n",
       "      <td>0.005546</td>\n",
       "      <td>-0.001830</td>\n",
       "      <td>0.494024</td>\n",
       "      <td>0.055056</td>\n",
       "      <td>0.071513</td>\n",
       "      <td>0.066218</td>\n",
       "      <td>0.469863</td>\n",
       "      <td>0.457827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.407731</td>\n",
       "      <td>0.324679</td>\n",
       "      <td>0.369069</td>\n",
       "      <td>0.451816</td>\n",
       "      <td>0.460669</td>\n",
       "      <td>0.450846</td>\n",
       "      <td>0.450141</td>\n",
       "      <td>0.453288</td>\n",
       "      <td>0.450251</td>\n",
       "      <td>0.450649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dp_000</th>\n",
       "      <td>0.269146</td>\n",
       "      <td>0.300123</td>\n",
       "      <td>0.121846</td>\n",
       "      <td>-0.001960</td>\n",
       "      <td>0.486012</td>\n",
       "      <td>0.054714</td>\n",
       "      <td>0.083098</td>\n",
       "      <td>0.076943</td>\n",
       "      <td>0.467008</td>\n",
       "      <td>0.455454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.381302</td>\n",
       "      <td>0.329460</td>\n",
       "      <td>0.372463</td>\n",
       "      <td>0.449281</td>\n",
       "      <td>0.459565</td>\n",
       "      <td>0.448473</td>\n",
       "      <td>0.447722</td>\n",
       "      <td>0.450595</td>\n",
       "      <td>0.447834</td>\n",
       "      <td>0.448244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dq_000</th>\n",
       "      <td>0.084778</td>\n",
       "      <td>0.121222</td>\n",
       "      <td>-0.016732</td>\n",
       "      <td>-0.000189</td>\n",
       "      <td>0.202257</td>\n",
       "      <td>0.004735</td>\n",
       "      <td>0.164375</td>\n",
       "      <td>0.157003</td>\n",
       "      <td>0.184809</td>\n",
       "      <td>0.191729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022502</td>\n",
       "      <td>0.127346</td>\n",
       "      <td>0.115591</td>\n",
       "      <td>0.159133</td>\n",
       "      <td>0.161133</td>\n",
       "      <td>0.159704</td>\n",
       "      <td>0.159670</td>\n",
       "      <td>0.158302</td>\n",
       "      <td>0.159700</td>\n",
       "      <td>0.159805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dr_000</th>\n",
       "      <td>0.149084</td>\n",
       "      <td>0.237327</td>\n",
       "      <td>-0.035686</td>\n",
       "      <td>-0.000611</td>\n",
       "      <td>0.390922</td>\n",
       "      <td>0.003247</td>\n",
       "      <td>0.208629</td>\n",
       "      <td>0.198070</td>\n",
       "      <td>0.361552</td>\n",
       "      <td>0.370696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.320338</td>\n",
       "      <td>0.251967</td>\n",
       "      <td>0.247565</td>\n",
       "      <td>0.291066</td>\n",
       "      <td>0.296580</td>\n",
       "      <td>0.290957</td>\n",
       "      <td>0.290910</td>\n",
       "      <td>0.289439</td>\n",
       "      <td>0.290970</td>\n",
       "      <td>0.291174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds_000</th>\n",
       "      <td>0.339790</td>\n",
       "      <td>0.364912</td>\n",
       "      <td>-0.059269</td>\n",
       "      <td>-0.001706</td>\n",
       "      <td>0.636580</td>\n",
       "      <td>0.055711</td>\n",
       "      <td>0.194644</td>\n",
       "      <td>0.185352</td>\n",
       "      <td>0.602745</td>\n",
       "      <td>0.592557</td>\n",
       "      <td>...</td>\n",
       "      <td>0.484417</td>\n",
       "      <td>0.452348</td>\n",
       "      <td>0.488931</td>\n",
       "      <td>0.553941</td>\n",
       "      <td>0.552836</td>\n",
       "      <td>0.553007</td>\n",
       "      <td>0.552486</td>\n",
       "      <td>0.554048</td>\n",
       "      <td>0.552605</td>\n",
       "      <td>0.553012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt_000</th>\n",
       "      <td>0.343902</td>\n",
       "      <td>0.360888</td>\n",
       "      <td>-0.045302</td>\n",
       "      <td>-0.001779</td>\n",
       "      <td>0.628908</td>\n",
       "      <td>0.052825</td>\n",
       "      <td>0.197615</td>\n",
       "      <td>0.188345</td>\n",
       "      <td>0.595581</td>\n",
       "      <td>0.585597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.488165</td>\n",
       "      <td>0.453240</td>\n",
       "      <td>0.486659</td>\n",
       "      <td>0.543979</td>\n",
       "      <td>0.545800</td>\n",
       "      <td>0.543230</td>\n",
       "      <td>0.542677</td>\n",
       "      <td>0.543918</td>\n",
       "      <td>0.542798</td>\n",
       "      <td>0.543205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>du_000</th>\n",
       "      <td>0.172052</td>\n",
       "      <td>0.190282</td>\n",
       "      <td>0.168394</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>0.362149</td>\n",
       "      <td>0.038878</td>\n",
       "      <td>0.039870</td>\n",
       "      <td>0.037173</td>\n",
       "      <td>0.351186</td>\n",
       "      <td>0.332954</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267108</td>\n",
       "      <td>0.293089</td>\n",
       "      <td>0.335677</td>\n",
       "      <td>0.369763</td>\n",
       "      <td>0.347019</td>\n",
       "      <td>0.369037</td>\n",
       "      <td>0.368374</td>\n",
       "      <td>0.371107</td>\n",
       "      <td>0.368468</td>\n",
       "      <td>0.368822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dv_000</th>\n",
       "      <td>0.207068</td>\n",
       "      <td>0.221422</td>\n",
       "      <td>0.075856</td>\n",
       "      <td>-0.001131</td>\n",
       "      <td>0.400757</td>\n",
       "      <td>0.056420</td>\n",
       "      <td>0.030165</td>\n",
       "      <td>0.028395</td>\n",
       "      <td>0.385610</td>\n",
       "      <td>0.362695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253475</td>\n",
       "      <td>0.313151</td>\n",
       "      <td>0.362927</td>\n",
       "      <td>0.421093</td>\n",
       "      <td>0.409773</td>\n",
       "      <td>0.419638</td>\n",
       "      <td>0.419052</td>\n",
       "      <td>0.422963</td>\n",
       "      <td>0.419146</td>\n",
       "      <td>0.419495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dx_000</th>\n",
       "      <td>0.143549</td>\n",
       "      <td>0.245748</td>\n",
       "      <td>-0.027228</td>\n",
       "      <td>-0.000448</td>\n",
       "      <td>0.391671</td>\n",
       "      <td>-0.001466</td>\n",
       "      <td>0.241406</td>\n",
       "      <td>0.228507</td>\n",
       "      <td>0.371879</td>\n",
       "      <td>0.386431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.311133</td>\n",
       "      <td>0.313564</td>\n",
       "      <td>0.297412</td>\n",
       "      <td>0.284009</td>\n",
       "      <td>0.284147</td>\n",
       "      <td>0.283974</td>\n",
       "      <td>0.283938</td>\n",
       "      <td>0.281918</td>\n",
       "      <td>0.283999</td>\n",
       "      <td>0.284214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dy_000</th>\n",
       "      <td>0.103488</td>\n",
       "      <td>0.166703</td>\n",
       "      <td>-0.027284</td>\n",
       "      <td>-0.000491</td>\n",
       "      <td>0.312565</td>\n",
       "      <td>0.001168</td>\n",
       "      <td>0.098849</td>\n",
       "      <td>0.093908</td>\n",
       "      <td>0.291156</td>\n",
       "      <td>0.290465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280843</td>\n",
       "      <td>0.224027</td>\n",
       "      <td>0.226234</td>\n",
       "      <td>0.271099</td>\n",
       "      <td>0.248776</td>\n",
       "      <td>0.270219</td>\n",
       "      <td>0.270042</td>\n",
       "      <td>0.271103</td>\n",
       "      <td>0.270095</td>\n",
       "      <td>0.270292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eb_000</th>\n",
       "      <td>0.156928</td>\n",
       "      <td>0.202855</td>\n",
       "      <td>-0.037743</td>\n",
       "      <td>-0.000701</td>\n",
       "      <td>0.358280</td>\n",
       "      <td>0.036010</td>\n",
       "      <td>0.083261</td>\n",
       "      <td>0.076967</td>\n",
       "      <td>0.328441</td>\n",
       "      <td>0.322859</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.268426</td>\n",
       "      <td>0.286006</td>\n",
       "      <td>0.293389</td>\n",
       "      <td>0.295912</td>\n",
       "      <td>0.292915</td>\n",
       "      <td>0.292631</td>\n",
       "      <td>0.293469</td>\n",
       "      <td>0.292694</td>\n",
       "      <td>0.292928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ec_00</th>\n",
       "      <td>0.317041</td>\n",
       "      <td>0.378670</td>\n",
       "      <td>-0.043352</td>\n",
       "      <td>-0.001104</td>\n",
       "      <td>0.586838</td>\n",
       "      <td>0.081259</td>\n",
       "      <td>0.230923</td>\n",
       "      <td>0.236797</td>\n",
       "      <td>0.588406</td>\n",
       "      <td>0.573606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268426</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.936366</td>\n",
       "      <td>0.675534</td>\n",
       "      <td>0.659744</td>\n",
       "      <td>0.674169</td>\n",
       "      <td>0.674427</td>\n",
       "      <td>0.676211</td>\n",
       "      <td>0.674192</td>\n",
       "      <td>0.674319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ed_000</th>\n",
       "      <td>0.358178</td>\n",
       "      <td>0.399766</td>\n",
       "      <td>-0.030470</td>\n",
       "      <td>-0.001242</td>\n",
       "      <td>0.611684</td>\n",
       "      <td>0.093644</td>\n",
       "      <td>0.217342</td>\n",
       "      <td>0.220481</td>\n",
       "      <td>0.611743</td>\n",
       "      <td>0.593201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286006</td>\n",
       "      <td>0.936366</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.708038</td>\n",
       "      <td>0.689033</td>\n",
       "      <td>0.706194</td>\n",
       "      <td>0.706502</td>\n",
       "      <td>0.709025</td>\n",
       "      <td>0.706216</td>\n",
       "      <td>0.706302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ag</th>\n",
       "      <td>0.507917</td>\n",
       "      <td>0.554594</td>\n",
       "      <td>-0.059616</td>\n",
       "      <td>-0.001617</td>\n",
       "      <td>0.810358</td>\n",
       "      <td>0.112506</td>\n",
       "      <td>0.336365</td>\n",
       "      <td>0.345878</td>\n",
       "      <td>0.819938</td>\n",
       "      <td>0.803068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293389</td>\n",
       "      <td>0.675534</td>\n",
       "      <td>0.708038</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986329</td>\n",
       "      <td>0.998937</td>\n",
       "      <td>0.999783</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.999691</td>\n",
       "      <td>0.998988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ay</th>\n",
       "      <td>0.485587</td>\n",
       "      <td>0.556873</td>\n",
       "      <td>-0.057979</td>\n",
       "      <td>-0.001619</td>\n",
       "      <td>0.797224</td>\n",
       "      <td>0.114615</td>\n",
       "      <td>0.348201</td>\n",
       "      <td>0.357369</td>\n",
       "      <td>0.807101</td>\n",
       "      <td>0.794086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.295912</td>\n",
       "      <td>0.659744</td>\n",
       "      <td>0.689033</td>\n",
       "      <td>0.986329</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987616</td>\n",
       "      <td>0.986655</td>\n",
       "      <td>0.985853</td>\n",
       "      <td>0.986556</td>\n",
       "      <td>0.987563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>az</th>\n",
       "      <td>0.510470</td>\n",
       "      <td>0.555756</td>\n",
       "      <td>-0.059176</td>\n",
       "      <td>-0.001608</td>\n",
       "      <td>0.809388</td>\n",
       "      <td>0.112121</td>\n",
       "      <td>0.341279</td>\n",
       "      <td>0.351221</td>\n",
       "      <td>0.818687</td>\n",
       "      <td>0.802303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.292915</td>\n",
       "      <td>0.674169</td>\n",
       "      <td>0.706194</td>\n",
       "      <td>0.998937</td>\n",
       "      <td>0.987616</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999031</td>\n",
       "      <td>0.998701</td>\n",
       "      <td>0.998941</td>\n",
       "      <td>0.999945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ba</th>\n",
       "      <td>0.511576</td>\n",
       "      <td>0.556104</td>\n",
       "      <td>-0.059913</td>\n",
       "      <td>-0.001614</td>\n",
       "      <td>0.809847</td>\n",
       "      <td>0.112029</td>\n",
       "      <td>0.343109</td>\n",
       "      <td>0.352831</td>\n",
       "      <td>0.819396</td>\n",
       "      <td>0.803215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.292631</td>\n",
       "      <td>0.674427</td>\n",
       "      <td>0.706502</td>\n",
       "      <td>0.999783</td>\n",
       "      <td>0.986655</td>\n",
       "      <td>0.999031</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999548</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.999141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cn</th>\n",
       "      <td>0.505155</td>\n",
       "      <td>0.553759</td>\n",
       "      <td>-0.059328</td>\n",
       "      <td>-0.001622</td>\n",
       "      <td>0.810432</td>\n",
       "      <td>0.113114</td>\n",
       "      <td>0.331530</td>\n",
       "      <td>0.340861</td>\n",
       "      <td>0.820002</td>\n",
       "      <td>0.802571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293469</td>\n",
       "      <td>0.676211</td>\n",
       "      <td>0.709025</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.985853</td>\n",
       "      <td>0.998701</td>\n",
       "      <td>0.999548</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999454</td>\n",
       "      <td>0.998767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs</th>\n",
       "      <td>0.511672</td>\n",
       "      <td>0.556079</td>\n",
       "      <td>-0.059876</td>\n",
       "      <td>-0.001614</td>\n",
       "      <td>0.809757</td>\n",
       "      <td>0.112049</td>\n",
       "      <td>0.343162</td>\n",
       "      <td>0.352881</td>\n",
       "      <td>0.819306</td>\n",
       "      <td>0.803134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.292694</td>\n",
       "      <td>0.674192</td>\n",
       "      <td>0.706216</td>\n",
       "      <td>0.999691</td>\n",
       "      <td>0.986556</td>\n",
       "      <td>0.998941</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.999454</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ee</th>\n",
       "      <td>0.510547</td>\n",
       "      <td>0.555908</td>\n",
       "      <td>-0.059683</td>\n",
       "      <td>-0.001613</td>\n",
       "      <td>0.809519</td>\n",
       "      <td>0.112120</td>\n",
       "      <td>0.341435</td>\n",
       "      <td>0.351370</td>\n",
       "      <td>0.818805</td>\n",
       "      <td>0.802434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.292928</td>\n",
       "      <td>0.674319</td>\n",
       "      <td>0.706302</td>\n",
       "      <td>0.998988</td>\n",
       "      <td>0.987563</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.999141</td>\n",
       "      <td>0.998767</td>\n",
       "      <td>0.999051</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           class    aa_000    ac_000    ad_000    ah_000    aj_000    al_000  \\\n",
       "class   1.000000  0.375922 -0.052777 -0.000567  0.525860  0.031937  0.374911   \n",
       "aa_000  0.375922  1.000000 -0.043109 -0.001051  0.571282  0.037383  0.307326   \n",
       "ac_000 -0.052777 -0.043109  1.000000 -0.001804 -0.068221 -0.009492 -0.043101   \n",
       "ad_000 -0.000567 -0.001051 -0.001804  1.000000 -0.001696 -0.000092 -0.000443   \n",
       "ah_000  0.525860  0.571282 -0.068221 -0.001696  1.000000  0.081498  0.424205   \n",
       "aj_000  0.031937  0.037383 -0.009492 -0.000092  0.081498  1.000000  0.007575   \n",
       "al_000  0.374911  0.307326 -0.043101 -0.000443  0.424205  0.007575  1.000000   \n",
       "am_0    0.383793  0.310554 -0.043575 -0.000447  0.429136  0.007588  0.989366   \n",
       "an_000  0.526455  0.575253 -0.062477 -0.001720  0.986293  0.084285  0.423010   \n",
       "ao_000  0.522661  0.578457 -0.064169 -0.001701  0.971470  0.068907  0.483840   \n",
       "ap_000  0.520655  0.516148 -0.065807 -0.001093  0.890870  0.095460  0.486568   \n",
       "aq_000  0.533687  0.489701 -0.049912 -0.001421  0.895490  0.103937  0.350945   \n",
       "av_000  0.123983  0.082758  0.015243 -0.000577  0.183375 -0.001185  0.071475   \n",
       "ax_000  0.108468  0.125917 -0.006992 -0.000877  0.229273 -0.003095  0.127473   \n",
       "bb_000  0.545215  0.574745 -0.065497 -0.001564  0.983440  0.087826  0.492423   \n",
       "bc_000  0.172855  0.180224 -0.021158 -0.000543  0.281033  0.001179  0.177739   \n",
       "bd_000  0.169845  0.215008 -0.016913 -0.000529  0.333786  0.011243  0.194446   \n",
       "be_000  0.117382  0.182129 -0.024964 -0.000570  0.278491  0.004011  0.216537   \n",
       "bf_000  0.195165  0.174637 -0.045399 -0.000560  0.312571  0.074014  0.093196   \n",
       "bg_000  0.525225  0.571234 -0.068399 -0.001698  0.998298  0.081486  0.425041   \n",
       "bh_000  0.503051  0.526941 -0.066424 -0.001513  0.951452  0.108889  0.367291   \n",
       "bi_000  0.436908  0.505887 -0.062591 -0.000926  0.831355  0.059669  0.425022   \n",
       "bj_000  0.528382  0.463157 -0.060836 -0.001095  0.830864  0.112002  0.474717   \n",
       "bk_000  0.082218  0.026487 -0.085762 -0.000869  0.049506  0.010934  0.048622   \n",
       "bl_000  0.046720  0.004669 -0.100134 -0.000937  0.014154  0.009996  0.028095   \n",
       "bm_000  0.031078 -0.007438 -0.103675 -0.000921 -0.005769  0.008548  0.019144   \n",
       "bn_000  0.020355 -0.014676 -0.105791 -0.000919 -0.018392  0.003944  0.010118   \n",
       "bo_000  0.011050 -0.021640 -0.102492 -0.000895 -0.030554  0.004378  0.003431   \n",
       "bs_000  0.200253  0.179588 -0.009803  0.005714  0.314344  0.030994  0.130473   \n",
       "bt_000  0.374552  0.999710 -0.043014 -0.001052  0.571495  0.037394  0.307419   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "ct_000  0.029529  0.033470  0.023714 -0.000338  0.085691  0.009307  0.024661   \n",
       "cu_000  0.071859  0.084755 -0.010076 -0.000477  0.161100  0.016532  0.096781   \n",
       "cv_000  0.224582  0.300415  0.017357 -0.002097  0.455983  0.009709  0.320119   \n",
       "cx_000  0.194742  0.269579 -0.025294 -0.000690  0.377566  0.002013  0.352167   \n",
       "cz_000  0.022330  0.045113  0.004219 -0.000262  0.106592  0.017296  0.018509   \n",
       "db_000 -0.017649  0.013762  0.043201 -0.000685 -0.003752  0.006277 -0.011249   \n",
       "dc_000  0.232068  0.308042  0.002190 -0.002255  0.480839  0.022018  0.309027   \n",
       "dd_000  0.288221  0.289924 -0.040591 -0.001145  0.543936  0.033206  0.234301   \n",
       "de_000  0.189567  0.155671 -0.014787 -0.000569  0.266978  0.008364  0.131669   \n",
       "dn_000  0.501021  0.491353 -0.056030 -0.001364  0.901856  0.140100  0.399615   \n",
       "do_000  0.285458  0.299866  0.005546 -0.001830  0.494024  0.055056  0.071513   \n",
       "dp_000  0.269146  0.300123  0.121846 -0.001960  0.486012  0.054714  0.083098   \n",
       "dq_000  0.084778  0.121222 -0.016732 -0.000189  0.202257  0.004735  0.164375   \n",
       "dr_000  0.149084  0.237327 -0.035686 -0.000611  0.390922  0.003247  0.208629   \n",
       "ds_000  0.339790  0.364912 -0.059269 -0.001706  0.636580  0.055711  0.194644   \n",
       "dt_000  0.343902  0.360888 -0.045302 -0.001779  0.628908  0.052825  0.197615   \n",
       "du_000  0.172052  0.190282  0.168394 -0.001426  0.362149  0.038878  0.039870   \n",
       "dv_000  0.207068  0.221422  0.075856 -0.001131  0.400757  0.056420  0.030165   \n",
       "dx_000  0.143549  0.245748 -0.027228 -0.000448  0.391671 -0.001466  0.241406   \n",
       "dy_000  0.103488  0.166703 -0.027284 -0.000491  0.312565  0.001168  0.098849   \n",
       "eb_000  0.156928  0.202855 -0.037743 -0.000701  0.358280  0.036010  0.083261   \n",
       "ec_00   0.317041  0.378670 -0.043352 -0.001104  0.586838  0.081259  0.230923   \n",
       "ed_000  0.358178  0.399766 -0.030470 -0.001242  0.611684  0.093644  0.217342   \n",
       "ag      0.507917  0.554594 -0.059616 -0.001617  0.810358  0.112506  0.336365   \n",
       "ay      0.485587  0.556873 -0.057979 -0.001619  0.797224  0.114615  0.348201   \n",
       "az      0.510470  0.555756 -0.059176 -0.001608  0.809388  0.112121  0.341279   \n",
       "ba      0.511576  0.556104 -0.059913 -0.001614  0.809847  0.112029  0.343109   \n",
       "cn      0.505155  0.553759 -0.059328 -0.001622  0.810432  0.113114  0.331530   \n",
       "cs      0.511672  0.556079 -0.059876 -0.001614  0.809757  0.112049  0.343162   \n",
       "ee      0.510547  0.555908 -0.059683 -0.001613  0.809519  0.112120  0.341435   \n",
       "\n",
       "            am_0    an_000    ao_000  ...    eb_000     ec_00    ed_000  \\\n",
       "class   0.383793  0.526455  0.522661  ...  0.156928  0.317041  0.358178   \n",
       "aa_000  0.310554  0.575253  0.578457  ...  0.202855  0.378670  0.399766   \n",
       "ac_000 -0.043575 -0.062477 -0.064169  ... -0.037743 -0.043352 -0.030470   \n",
       "ad_000 -0.000447 -0.001720 -0.001701  ... -0.000701 -0.001104 -0.001242   \n",
       "ah_000  0.429136  0.986293  0.971470  ...  0.358280  0.586838  0.611684   \n",
       "aj_000  0.007588  0.084285  0.068907  ...  0.036010  0.081259  0.093644   \n",
       "al_000  0.989366  0.423010  0.483840  ...  0.083261  0.230923  0.217342   \n",
       "am_0    1.000000  0.424572  0.486244  ...  0.076967  0.236797  0.220481   \n",
       "an_000  0.424572  1.000000  0.989841  ...  0.328441  0.588406  0.611743   \n",
       "ao_000  0.486244  0.989841  1.000000  ...  0.322859  0.573606  0.593201   \n",
       "ap_000  0.507278  0.879295  0.845373  ...  0.244320  0.571326  0.578484   \n",
       "aq_000  0.372881  0.868907  0.818655  ...  0.265829  0.534388  0.560887   \n",
       "av_000  0.069646  0.171824  0.162682  ...  0.119929  0.149503  0.160584   \n",
       "ax_000  0.122385  0.222783  0.222735  ...  0.159275  0.187368  0.200991   \n",
       "bb_000  0.502012  0.985959  0.974705  ...  0.309016  0.596115  0.613726   \n",
       "bc_000  0.165891  0.272160  0.284712  ...  0.224643  0.201521  0.213167   \n",
       "bd_000  0.181540  0.318465  0.329595  ...  0.271407  0.246407  0.256945   \n",
       "be_000  0.205226  0.267735  0.280333  ...  0.182078  0.239049  0.225222   \n",
       "bf_000  0.089026  0.288052  0.270706  ...  0.185795  0.221827  0.247134   \n",
       "bg_000  0.427158  0.988065  0.971138  ...  0.358304  0.586122  0.611498   \n",
       "bh_000  0.375571  0.933295  0.893043  ...  0.307766  0.572159  0.595000   \n",
       "bi_000  0.441020  0.828154  0.817755  ...  0.270414  0.572995  0.568583   \n",
       "bj_000  0.505012  0.810056  0.772423  ...  0.193726  0.496983  0.512613   \n",
       "bk_000  0.054447  0.039278  0.027390  ...  0.006258  0.059059  0.057238   \n",
       "bl_000  0.032712  0.004283 -0.005073  ... -0.000585  0.033319  0.030201   \n",
       "bm_000  0.023412 -0.015348 -0.023104  ... -0.002563  0.016896  0.012994   \n",
       "bn_000  0.014294 -0.027948 -0.034500  ... -0.006918  0.002534 -0.002283   \n",
       "bo_000  0.007476 -0.040226 -0.046283  ... -0.008453 -0.005926 -0.011131   \n",
       "bs_000  0.136849  0.306732  0.286912  ...  0.121883  0.222646  0.238587   \n",
       "bt_000  0.310642  0.575469  0.578673  ...  0.202954  0.378895  0.399955   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "ct_000  0.026067  0.077703  0.068370  ...  0.044892  0.088157  0.091718   \n",
       "cu_000  0.101437  0.154404  0.151876  ...  0.080263  0.139195  0.135868   \n",
       "cv_000  0.321431  0.458054  0.477810  ...  0.234826  0.376461  0.362734   \n",
       "cx_000  0.349544  0.381393  0.409986  ...  0.193384  0.306795  0.281128   \n",
       "cz_000  0.019382  0.097020  0.089299  ...  0.066693  0.095203  0.092754   \n",
       "db_000 -0.011277 -0.000726 -0.001470  ... -0.008087  0.036320  0.036455   \n",
       "dc_000  0.310857  0.479778  0.494328  ...  0.247672  0.396900  0.382758   \n",
       "dd_000  0.228353  0.524810  0.509742  ...  0.315521  0.416890  0.441382   \n",
       "de_000  0.126327  0.252747  0.249474  ...  0.247906  0.193569  0.213306   \n",
       "dn_000  0.408378  0.865021  0.817948  ...  0.289308  0.550363  0.577042   \n",
       "do_000  0.066218  0.469863  0.457827  ...  0.407731  0.324679  0.369069   \n",
       "dp_000  0.076943  0.467008  0.455454  ...  0.381302  0.329460  0.372463   \n",
       "dq_000  0.157003  0.184809  0.191729  ...  0.022502  0.127346  0.115591   \n",
       "dr_000  0.198070  0.361552  0.370696  ...  0.320338  0.251967  0.247565   \n",
       "ds_000  0.185352  0.602745  0.592557  ...  0.484417  0.452348  0.488931   \n",
       "dt_000  0.188345  0.595581  0.585597  ...  0.488165  0.453240  0.486659   \n",
       "du_000  0.037173  0.351186  0.332954  ...  0.267108  0.293089  0.335677   \n",
       "dv_000  0.028395  0.385610  0.362695  ...  0.253475  0.313151  0.362927   \n",
       "dx_000  0.228507  0.371879  0.386431  ...  0.311133  0.313564  0.297412   \n",
       "dy_000  0.093908  0.291156  0.290465  ...  0.280843  0.224027  0.226234   \n",
       "eb_000  0.076967  0.328441  0.322859  ...  1.000000  0.268426  0.286006   \n",
       "ec_00   0.236797  0.588406  0.573606  ...  0.268426  1.000000  0.936366   \n",
       "ed_000  0.220481  0.611743  0.593201  ...  0.286006  0.936366  1.000000   \n",
       "ag      0.345878  0.819938  0.803068  ...  0.293389  0.675534  0.708038   \n",
       "ay      0.357369  0.807101  0.794086  ...  0.295912  0.659744  0.689033   \n",
       "az      0.351221  0.818687  0.802303  ...  0.292915  0.674169  0.706194   \n",
       "ba      0.352831  0.819396  0.803215  ...  0.292631  0.674427  0.706502   \n",
       "cn      0.340861  0.820002  0.802571  ...  0.293469  0.676211  0.709025   \n",
       "cs      0.352881  0.819306  0.803134  ...  0.292694  0.674192  0.706216   \n",
       "ee      0.351370  0.818805  0.802434  ...  0.292928  0.674319  0.706302   \n",
       "\n",
       "              ag        ay        az        ba        cn        cs        ee  \n",
       "class   0.507917  0.485587  0.510470  0.511576  0.505155  0.511672  0.510547  \n",
       "aa_000  0.554594  0.556873  0.555756  0.556104  0.553759  0.556079  0.555908  \n",
       "ac_000 -0.059616 -0.057979 -0.059176 -0.059913 -0.059328 -0.059876 -0.059683  \n",
       "ad_000 -0.001617 -0.001619 -0.001608 -0.001614 -0.001622 -0.001614 -0.001613  \n",
       "ah_000  0.810358  0.797224  0.809388  0.809847  0.810432  0.809757  0.809519  \n",
       "aj_000  0.112506  0.114615  0.112121  0.112029  0.113114  0.112049  0.112120  \n",
       "al_000  0.336365  0.348201  0.341279  0.343109  0.331530  0.343162  0.341435  \n",
       "am_0    0.345878  0.357369  0.351221  0.352831  0.340861  0.352881  0.351370  \n",
       "an_000  0.819938  0.807101  0.818687  0.819396  0.820002  0.819306  0.818805  \n",
       "ao_000  0.803068  0.794086  0.802303  0.803215  0.802571  0.803134  0.802434  \n",
       "ap_000  0.769171  0.756758  0.769056  0.769580  0.768547  0.769503  0.769196  \n",
       "aq_000  0.779581  0.756226  0.779027  0.779201  0.780112  0.779104  0.779118  \n",
       "av_000  0.197286  0.178445  0.197942  0.197626  0.197253  0.197675  0.197858  \n",
       "ax_000  0.216158  0.208828  0.216996  0.216792  0.215482  0.216849  0.217042  \n",
       "bb_000  0.823592  0.812097  0.823060  0.823819  0.823152  0.823736  0.823198  \n",
       "bc_000  0.218568  0.218976  0.218871  0.218839  0.217287  0.218884  0.219047  \n",
       "bd_000  0.260631  0.262987  0.260906  0.260776  0.259469  0.260835  0.261041  \n",
       "be_000  0.219668  0.222318  0.219578  0.219452  0.218185  0.219501  0.219668  \n",
       "bf_000  0.318695  0.321939  0.318154  0.317821  0.318754  0.317885  0.318117  \n",
       "bg_000  0.810027  0.796291  0.808930  0.809386  0.810154  0.809296  0.809058  \n",
       "bh_000  0.802951  0.789357  0.801518  0.802085  0.803462  0.801961  0.801651  \n",
       "bi_000  0.702338  0.691553  0.701440  0.702010  0.701977  0.701992  0.701581  \n",
       "bj_000  0.733674  0.721781  0.734449  0.734869  0.732784  0.734756  0.734570  \n",
       "bk_000  0.051050  0.049240  0.051419  0.051361  0.050656  0.051403  0.051311  \n",
       "bl_000  0.017608  0.016031  0.017917  0.017769  0.017324  0.017819  0.017745  \n",
       "bm_000 -0.000203 -0.001174  0.000151 -0.000031 -0.000488  0.000010 -0.000047  \n",
       "bn_000 -0.011678 -0.012611 -0.011286 -0.011540 -0.011889 -0.011514 -0.011500  \n",
       "bo_000 -0.023398 -0.024015 -0.023039 -0.023277 -0.023605 -0.023253 -0.023257  \n",
       "bs_000  0.298274  0.295110  0.297957  0.297847  0.298447  0.297881  0.297815  \n",
       "bt_000  0.554383  0.556616  0.555520  0.555888  0.553562  0.555863  0.555679  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "ct_000  0.124225  0.119506  0.124124  0.124014  0.124588  0.124044  0.124064  \n",
       "cu_000  0.224859  0.230281  0.225315  0.225370  0.224703  0.225418  0.225317  \n",
       "cv_000  0.411446  0.423082  0.412267  0.412487  0.409412  0.412569  0.412260  \n",
       "cx_000  0.329950  0.339992  0.331126  0.331454  0.327325  0.331523  0.331297  \n",
       "cz_000  0.175403  0.177164  0.174770  0.174593  0.176317  0.174629  0.174753  \n",
       "db_000  0.024224  0.025851  0.024255  0.023978  0.023750  0.023999  0.024093  \n",
       "dc_000  0.457684  0.468830  0.458321  0.458496  0.456015  0.458576  0.458342  \n",
       "dd_000  0.489777  0.483869  0.489524  0.489100  0.489190  0.489201  0.489555  \n",
       "de_000  0.203269  0.207763  0.203894  0.203763  0.202329  0.203809  0.203977  \n",
       "dn_000  0.772783  0.757056  0.771846  0.772281  0.773348  0.772206  0.771981  \n",
       "do_000  0.451816  0.460669  0.450846  0.450141  0.453288  0.450251  0.450649  \n",
       "dp_000  0.449281  0.459565  0.448473  0.447722  0.450595  0.447834  0.448244  \n",
       "dq_000  0.159133  0.161133  0.159704  0.159670  0.158302  0.159700  0.159805  \n",
       "dr_000  0.291066  0.296580  0.290957  0.290910  0.289439  0.290970  0.291174  \n",
       "ds_000  0.553941  0.552836  0.553007  0.552486  0.554048  0.552605  0.553012  \n",
       "dt_000  0.543979  0.545800  0.543230  0.542677  0.543918  0.542798  0.543205  \n",
       "du_000  0.369763  0.347019  0.369037  0.368374  0.371107  0.368468  0.368822  \n",
       "dv_000  0.421093  0.409773  0.419638  0.419052  0.422963  0.419146  0.419495  \n",
       "dx_000  0.284009  0.284147  0.283974  0.283938  0.281918  0.283999  0.284214  \n",
       "dy_000  0.271099  0.248776  0.270219  0.270042  0.271103  0.270095  0.270292  \n",
       "eb_000  0.293389  0.295912  0.292915  0.292631  0.293469  0.292694  0.292928  \n",
       "ec_00   0.675534  0.659744  0.674169  0.674427  0.676211  0.674192  0.674319  \n",
       "ed_000  0.708038  0.689033  0.706194  0.706502  0.709025  0.706216  0.706302  \n",
       "ag      1.000000  0.986329  0.998937  0.999783  0.999885  0.999691  0.998988  \n",
       "ay      0.986329  1.000000  0.987616  0.986655  0.985853  0.986556  0.987563  \n",
       "az      0.998937  0.987616  1.000000  0.999031  0.998701  0.998941  0.999945  \n",
       "ba      0.999783  0.986655  0.999031  1.000000  0.999548  0.999900  0.999141  \n",
       "cn      0.999885  0.985853  0.998701  0.999548  1.000000  0.999454  0.998767  \n",
       "cs      0.999691  0.986556  0.998941  0.999900  0.999454  1.000000  0.999051  \n",
       "ee      0.998988  0.987563  0.999945  0.999141  0.998767  0.999051  1.000000  \n",
       "\n",
       "[80 rows x 80 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor = 0\n",
    "if (RunCorrelationAnalysis == True):\n",
    "    #print(\"RunCorrelationAnalysis On\")\n",
    "    #### Filter Method for Feature Correlation with Class Feature\n",
    "    #Using Pearson Correlation\n",
    "    #plt.figure(figsize=(12,10))\n",
    "    cor = train.corr()\n",
    "    #sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n",
    "    #plt.show()\n",
    "cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class     1.000000\n",
      "ci_000    0.570383\n",
      "bb_000    0.545215\n",
      "bv_000    0.543530\n",
      "bu_000    0.543529\n",
      "cq_000    0.543529\n",
      "aq_000    0.533687\n",
      "cc_000    0.530158\n",
      "bj_000    0.528382\n",
      "an_000    0.526455\n",
      "ah_000    0.525860\n",
      "bg_000    0.525225\n",
      "bx_000    0.523317\n",
      "ao_000    0.522661\n",
      "by_000    0.521415\n",
      "ap_000    0.520655\n",
      "cs        0.511672\n",
      "ba        0.511576\n",
      "ee        0.510547\n",
      "az        0.510470\n",
      "ag        0.507917\n",
      "cn        0.505155\n",
      "bh_000    0.503051\n",
      "dn_000    0.501021\n",
      "ay        0.485587\n",
      "ck_000    0.477137\n",
      "bi_000    0.436908\n",
      "Name: class, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "if (RunCorrelationAnalysis == True):\n",
    "    #Correlation with output variable\n",
    "    cor_target = abs(cor[\"class\"])\n",
    "    #Selecting highly correlated features\n",
    "    relevant_features = cor_target[cor_target>0.4]\n",
    "    print(relevant_features.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corr_FeatureSelection = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(57000, 6)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if (Corr_FeatureSelection == 1):\n",
    "    print(\"Corr_FeatureSelection = 1\")\n",
    "    #Most correlated features with class (>0.4)\n",
    "    train = train[['class','aa_000','ah_000','an_000',\\\n",
    "                         'ao_000','ap_000','aq_000',\\\n",
    "                         'bb_000','bg_000','bh_000',\\\n",
    "                         'bi_000','bj_000','bt_000',\\\n",
    "                         'bu_000','bv_000','bx_000',\\\n",
    "                         'by_000','cc_000','ci_000',\\\n",
    "                         'ck_000','cq_000','cv_000',\\\n",
    "                         'dc_000','dn_000','ds_000',\\\n",
    "                         'dt_000','ed_000','ag',\\\n",
    "                         'ay','az','ba',\\\n",
    "                         'cn','cs','ee']].copy()\n",
    "    \n",
    "    test = test[['class','aa_000','ah_000','an_000',\\\n",
    "                         'ao_000','ap_000','aq_000',\\\n",
    "                         'bb_000','bg_000','bh_000',\\\n",
    "                         'bi_000','bj_000','bt_000',\\\n",
    "                         'bu_000','bv_000','bx_000',\\\n",
    "                         'by_000','cc_000','ci_000',\\\n",
    "                         'ck_000','cq_000','cv_000',\\\n",
    "                         'dc_000','dn_000','ds_000',\\\n",
    "                         'dt_000','ed_000','ag',\\\n",
    "                         'ay','az','ba',\\\n",
    "                         'cn','cs','ee']].copy()\n",
    "\n",
    "    \n",
    "if (Corr_FeatureSelection == 2):\n",
    "    print(\"Corr_FeatureSelection = 2\")\n",
    "    \n",
    "    train = train[['class','bb_000','ck_000','dc_000','ed_000','ba']].copy()\n",
    "    test = test[['class','bb_000','ck_000','dc_000','ed_000','ba']].copy()\n",
    "    \n",
    "    \n",
    "if (Corr_FeatureSelection == 3):\n",
    "    print(\"Corr_FeatureSelection = 3\")\n",
    "    \n",
    "    train = train[['class','ck_000','dc_000','ed_000','ba']].copy()\n",
    "    test = test[['class','ck_000','dc_000','ed_000','ba']].copy()\n",
    "    \n",
    "\n",
    "    \n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x1800 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if (RunCorrelationAnalysis == True):\n",
    "    #Using Pearson Correlation\n",
    "    plt.figure(figsize=(40,25))\n",
    "    cor2 = train.corr()\n",
    "    sns.heatmap(cor2, annot=True, cmap=plt.cm.Reds)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsampling On\n",
      "ADASYN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0    55968\n",
       "1.0    44838\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if (Upsampling == True):\n",
    "    print(\"Upsampling On\")\n",
    "\n",
    "    train_Labels = train[\"class\"]\n",
    "    columnsNames = list(train.columns.values)\n",
    "\n",
    "    # Oversampling minority class points, here minority class points are 1s\n",
    "    if (UpsamplingAproach == \"ADASYN\"):\n",
    "        print(\"ADASYN\")\n",
    "        ada = ADASYN(sampling_strategy = _sampling_strategy)\n",
    "        train_balanced, train_3_3_balanced_Labels = ada.fit_sample(train, train_Labels)\n",
    "    if(UpsamplingAproach == \"SMOTE\"):\n",
    "        print(\"SMOTE\")\n",
    "        sm = SMOTE(sampling_strategy = _sampling_strategy)\n",
    "        train_balanced, train_3_3_balanced_Labels = sm.fit_sample(train, train_Labels)\n",
    "\n",
    "    train = pd.DataFrame(train_balanced, columns=columnsNames)\n",
    "\n",
    "train[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest, SVM, Bagging, GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, make_scorer\n",
    "import scikitplot as skplt\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100806, 6)\n"
     ]
    }
   ],
   "source": [
    "train_4model = train.copy()\n",
    "pred_4model = test.copy()\n",
    "pred_4model['class'] = \"\"\n",
    "\n",
    "X = train_4model.drop('class', axis=1) \n",
    "y = train_4model['class']\n",
    "\n",
    "X_pred = pred_4model.drop('class', axis=1)\n",
    "#y_pred = test_4model['class']\n",
    "\n",
    "print (train_4model.shape)\n",
    "#print (test_4model.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Bagging On\n"
     ]
    }
   ],
   "source": [
    "# Definition of the models\n",
    "\n",
    "cost_score = make_scorer((getCost),greater_is_better = False)\n",
    "\n",
    "\n",
    "if (GridSearch == True):\n",
    "    \n",
    "    if (ModelToUse == \"SVM\"):\n",
    "        print(\"GridSearch SVM\")\n",
    "        model_SVM = GridSearchCV(svm.SVC(), param_grid= ParamGrid_SVM, scoring= cost_score, verbose=_verbose, cv=_cv)\n",
    "        \n",
    "        model_bagging = model_SVM\n",
    "        \n",
    "    if (ModelToUse == \"RF\"):\n",
    "        print(\"GridSearch RF\")\n",
    "        rf = RandomForestClassifier()\n",
    "        model_RF = GridSearchCV(rf, param_grid= ParamGrid_RF, scoring= cost_score, verbose=_verbose, cv=_cv)\n",
    "        \n",
    "        model_bagging = model_RF\n",
    "else:\n",
    "    \n",
    "    if (ModelToUse == \"RF\"):\n",
    "        print(\"Random Forest\")\n",
    "\n",
    "        model_RF = RandomForestClassifier(max_depth=_max_depth,n_estimators=_n_estimators, \\\n",
    "                                                bootstrap=_bootstrap, class_weight=_class_weight, \\\n",
    "                                                random_state=_SEED, n_jobs=_n_jobs)\n",
    "        model_bagging = model_RF\n",
    "\n",
    "    if (ModelToUse == \"SVM\"):\n",
    "        print(\"SVM\")\n",
    "        #model_SVM = svm.SVC(gamma=1)\n",
    "        model_SVM = svm.SVC(C=_C, kernel=_kernel, degree=_degree, gamma=_gamma, coef0=_coef0, \\\n",
    "                            shrinking=_shrinking, probability=_probability, tol=_tol, cache_size=_cache_size, \\\n",
    "                            class_weight=None, verbose=False, max_iter=-1, \\\n",
    "                            decision_function_shape=_decision_function_shape, random_state=_random_state)\n",
    "\n",
    "        model_bagging = model_SVM\n",
    "\n",
    "if (Bagging == True):\n",
    "    print(\"Bagging On\")\n",
    "    \n",
    "    model_bagging_rf = BaggingClassifier(model_bagging, n_estimators=_n_estimators, \\\n",
    "                                         max_samples=_max_samples, max_features=_max_features, \\\n",
    "                                         bootstrap=_bootstrap, bootstrap_features=_bootstrap_features, \\\n",
    "                                         oob_score=_oob_score, warm_start=_warm_start, n_jobs=_n_jobs, \\\n",
    "                                         random_state=_random_state, verbose=_verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test splitting On\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    5.7s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9408788810633866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "if (EnableSplitting == True):\n",
    "    print(\"Train/Test splitting On\")\n",
    "    # Separating our data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=_test_size, stratify=y, random_state=_SEED)\n",
    "\n",
    "\n",
    "if (UseExistingModel == False):\n",
    "    if (Bagging == True):\n",
    "\n",
    "        if (EnableSplitting == True):\n",
    "            model_final = model_bagging_rf.fit(X_train, y_train)\n",
    "            print(model_bagging_rf.score(X_test, y_test))\n",
    "\n",
    "        else:\n",
    "            model_final = model_bagging_rf.fit(X, y)\n",
    "\n",
    "    else:    # Random Forest and SVM\n",
    "        if (ModelToUse == \"RF\"):\n",
    "            if (EnableSplitting == True):\n",
    "                model_final = model_RF.fit(X_train, y_train)\n",
    "                print(model_RF.score(X_test, y_test))\n",
    "            else:\n",
    "                model_final = model_RF.fit(X, y)\n",
    "        if (ModelToUse == \"SVM\"):\n",
    "            if (EnableSplitting == True):\n",
    "                model_final = model_SVM.fit(X_train, y_train)\n",
    "                print(model_SVM.score(X_test, y_test))\n",
    "            else:\n",
    "                model_final = model_SVM.fit(X, y)\n",
    "else:\n",
    "    print('Using model: ' + ModelName)\n",
    "    model_final = load(ModelName)\n",
    "    print(model_final.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if(EnableSplitting == True):\n",
    "    # Confusion Matrix\n",
    "    y_pred = model_final.predict(X_test)\n",
    "    y_pred_proba = model_final.predict_proba(X_test)\n",
    "    # the confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    # visualizing the matrix\n",
    "    skplt.metrics.plot_confusion_matrix(y_test, y_pred, normalize=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1924600\n"
     ]
    }
   ],
   "source": [
    "print (getCost(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "#### Evaluating Test dataset and generating \"prediction_results.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    17563\n",
      "1.0     1437\n",
      "Name: Predicted, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_final.predict(X_pred)\n",
    "res = pd.DataFrame(y_pred)\n",
    "res.columns = [\"Predicted\"]\n",
    "res.index.name = \"Id\"\n",
    "\n",
    "if (FavorTrueClass == True):\n",
    "    print(\"FavorTrueClass correction On\")\n",
    "    \n",
    "    y_pred_proba = model_final.predict_proba(X_pred)\n",
    "    res_p = pd.DataFrame(y_pred_proba)\n",
    "    res2 = res.copy()\n",
    "    res2['Predicted'] = res_p.apply(lambda x: FavorTrues(x[1]), axis=1)\n",
    "    res2.index = X_pred.index + 1 \n",
    "    res2.index.name = \"Id\"\n",
    "    print(res2['Predicted'].value_counts())\n",
    "\n",
    "res.index = X_pred.index + 1\n",
    "res.index.name = \"Id\"\n",
    "print(res['Predicted'].value_counts())\n",
    "\n",
    "if (FavorTrueClass == True):\n",
    "    res = res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SaveToFile On\n",
      "\n",
      "      Predicted\n",
      "Id             \n",
      "1         false\n",
      "2         false\n",
      "3         false\n",
      "4         false\n",
      "5         false\n",
      "6         false\n",
      "7         false\n",
      "8         false\n",
      "9         false\n",
      "10         true\n",
      "11        false\n",
      "12        false\n",
      "13        false\n",
      "14        false\n",
      "15        false\n",
      "16        false\n",
      "17        false\n",
      "18        false\n",
      "19        false\n",
      "20        false\n",
      "21         true\n",
      "22        false\n",
      "23        false\n",
      "24        false\n",
      "25        false\n",
      "26        false\n",
      "27        false\n",
      "28        false\n",
      "29        false\n",
      "30        false\n",
      "...         ...\n",
      "18971     false\n",
      "18972     false\n",
      "18973     false\n",
      "18974      true\n",
      "18975     false\n",
      "18976     false\n",
      "18977     false\n",
      "18978     false\n",
      "18979     false\n",
      "18980     false\n",
      "18981     false\n",
      "18982     false\n",
      "18983     false\n",
      "18984     false\n",
      "18985     false\n",
      "18986     false\n",
      "18987     false\n",
      "18988     false\n",
      "18989     false\n",
      "18990     false\n",
      "18991     false\n",
      "18992      true\n",
      "18993     false\n",
      "18994     false\n",
      "18995     false\n",
      "18996     false\n",
      "18997     false\n",
      "18998     false\n",
      "18999     false\n",
      "19000     false\n",
      "\n",
      "[19000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "res.sort_index(inplace=True)\n",
    "\n",
    "if (FavorTrueClass == False):\n",
    "    res['Predicted'].replace(to_replace = 1, value = \"true\", inplace = True)\n",
    "    res['Predicted'].replace(to_replace = 0, value = \"false\", inplace = True)\n",
    "\n",
    "if (SaveToFile == True):\n",
    "    print(\"SaveToFile On\")\n",
    "    print(\"\")\n",
    "    res.to_csv(FileName)\n",
    "\n",
    "    'Saving Model'\n",
    "    #dump(model_final, modelFileName) \n",
    "    \n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Beep()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Kaggle uploads\n",
    "\n",
    "-31.43157\n",
    "train_3_3_bal\n",
    "max_depth=6,n_estimators=100, bootstrap=True, class_weight='balanced', random_state=SEED, n_jobs=-1\n",
    "\n",
    "-12.28421\n",
    "199 166\n",
    "train_3_3_bal\n",
    "max_depth=5,n_estimators=100, bootstrap=True, class_weight='balanced', random_state=SEED, n_jobs=-1\n",
    "\n",
    "\n",
    "25NOV19\n",
    "-----------------------\n",
    "-----------------------\n",
    "-9.01052\n",
    "-----------------------\n",
    "-----------------------\n",
    "#### Exploratory \n",
    "AnalysisAnalysis = False\n",
    "\n",
    "#### Column Removal\n",
    "Remove_Cols_with_many_bad_data = True\n",
    "NaN_Zero_Threshold = 0.8\n",
    "\n",
    "#### Outliers\n",
    "RemoveOutliers = False    #Using IQR\n",
    "Times_IQR = 1.5           #Normal factor (1.5). Kills minority class if class included!!\n",
    "## Outliers by class\n",
    "RemoveOutliers_PositiveClass = False\n",
    "RemoveOutliers_NegativeClass = False  #It removes >90% of the class\n",
    "\n",
    "#### NaN and Zero replacement\n",
    "NaN_Zero_Replacement = True\n",
    "NaN_Zero_Replacement_Mode = 'perClass' #general or perClass\n",
    "NaN_Zero_Replacement_Operation = 'median' #median or mean\n",
    "NaN_Zero_Replacement_Sort = True\n",
    "\n",
    "#### Data ProjectionsProjectBins = True\n",
    "ProjectBin_Operation = \"mean\"  #sum or mean\n",
    "RemoveSubBins = True\n",
    "\n",
    "#### Rounding values\n",
    "Rounding = True     #Does not change the results and makes the process faster\n",
    "RoudingDecimals = 2\n",
    "\n",
    "#### Feature Selection\n",
    "RunCorrelationAnalysis = False   #Using Pearson Correlation\n",
    "Corr_FeatureSelection = 1   #0, 1, 2, 3, 4\n",
    "\n",
    "#### Resampling\n",
    "Upsampling = True\n",
    "\n",
    "#### Random Forest Parameters\n",
    "# Train-Test split\n",
    "_test_size = 0.2\n",
    "# RF\n",
    "_max_depth = 5\n",
    "_n_estimators = 100\n",
    "_bootstrap = True\n",
    "_class_weight ='balanced'\n",
    "_SEED = 1\n",
    "_n_jobs = -1\n",
    "\n",
    "\n",
    "\n",
    "Last changes\n",
    "------------\n",
    "Reduced split train/test to 5%\n",
    "Favor of True Class by 5%\n",
    "\n",
    "26NOV19-1\n",
    "-----------------------\n",
    "-----------------------\n",
    "-8.23157\n",
    "-----------------------\n",
    "-----------------------\n",
    "#### Exploratory Analysis\n",
    "Analysis = False\n",
    "\n",
    "#### Column Removal\n",
    "Remove_Cols_with_many_bad_data = True\n",
    "NaN_Zero_Threshold = 0.8\n",
    "\n",
    "#### Outliers\n",
    "RemoveOutliers = False    #Using IQR\n",
    "Times_IQR = 1.5           #Normal factor (1.5). Kills minority class if class included!!\n",
    "\n",
    "## Outliers by class\n",
    "RemoveOutliers_PositiveClass = False\n",
    "RemoveOutliers_NegativeClass = False  #It removes >90% of the class\n",
    "\n",
    "#### NaN and Zero replacement\n",
    "NaN_Zero_Replacement = True\n",
    "NaN_Zero_Replacement_Mode = 'perClass' #general or perClass\n",
    "NaN_Zero_Replacement_Operation = 'median' #median or mean\n",
    "NaN_Zero_Replacement_Sort = True\n",
    "\n",
    "#### Data Projections\n",
    "ProjectBins = True\n",
    "ProjectBin_Operation = \"mean\"  #sum or mean\n",
    "RemoveSubBins = True\n",
    "\n",
    "#### Rounding values\n",
    "Rounding = True     #Does not change the results and makes the process faster\n",
    "RoudingDecimals = 2\n",
    "\n",
    "#### Feature Selection\n",
    "RunCorrelationAnalysis = False   #Using Pearson Correlation\n",
    "Corr_FeatureSelection = 1   #0, 1, 2, 3, 4\n",
    "\n",
    "#### Resampling\n",
    "Upsampling = True\n",
    "\n",
    "#### Random Forest Parameters\n",
    "# Train-Test split\n",
    "_test_size = 0.05\n",
    "# RF\n",
    "_max_depth = 5\n",
    "_n_estimators = 100\n",
    "_bootstrap = True\n",
    "_class_weight ='balanced'\n",
    "_SEED = 1\n",
    "_n_jobs = -1\n",
    "\n",
    "#### After prediction\n",
    "FavorTrueClass = True\n",
    "FavorThreshold = 0.45\n",
    "\n",
    "SaveToFile = True \n",
    "\n",
    "\n",
    "Last changes\n",
    "------------\n",
    "Changed -> FavorTrueClass = False\n",
    "To make sure that it was an improvement, it is, \n",
    "so I will decrease the threshold for tomorrow\n",
    "\n",
    "26NOV19-2\n",
    "-----------------------\n",
    "-----------------------\n",
    "-9.00000\n",
    "-----------------------\n",
    "-----------------------\n",
    "#### Exploratory Analysis\n",
    "Analysis = False\n",
    "\n",
    "#### Column Removal\n",
    "Remove_Cols_with_many_bad_data = True\n",
    "NaN_Zero_Threshold = 0.8\n",
    "\n",
    "#### Outliers\n",
    "RemoveOutliers = False    #Using IQR\n",
    "Times_IQR = 1.5           #Normal factor (1.5). Kills minority class if class included!!\n",
    "\n",
    "## Outliers by class\n",
    "RemoveOutliers_PositiveClass = False\n",
    "RemoveOutliers_NegativeClass = False  #It removes >90% of the class\n",
    "\n",
    "#### NaN and Zero replacement\n",
    "NaN_Zero_Replacement = True\n",
    "NaN_Zero_Replacement_Mode = 'perClass' #general or perClass\n",
    "NaN_Zero_Replacement_Operation = 'median' #median or mean\n",
    "NaN_Zero_Replacement_Sort = True\n",
    "\n",
    "#### Data Projections\n",
    "ProjectBins = True\n",
    "ProjectBin_Operation = \"mean\"  #sum or mean\n",
    "RemoveSubBins = True\n",
    "\n",
    "#### Rounding values\n",
    "Rounding = True     #Does not change the results and makes the process faster\n",
    "RoudingDecimals = 2\n",
    "\n",
    "#### Feature Selection\n",
    "RunCorrelationAnalysis = False   #Using Pearson Correlation\n",
    "Corr_FeatureSelection = 1   #0, 1, 2, 3, 4\n",
    "\n",
    "#### Resampling\n",
    "Upsampling = True\n",
    "\n",
    "#### Random Forest Parameters\n",
    "# Train-Test split\n",
    "_test_size = 0.05\n",
    "# RF\n",
    "_max_depth = 5\n",
    "_n_estimators = 100\n",
    "_bootstrap = True\n",
    "_class_weight ='balanced'\n",
    "_SEED = 1\n",
    "_n_jobs = -1\n",
    "\n",
    "#### After prediction\n",
    "FavorTrueClass = False\n",
    "FavorThreshold = 0.45\n",
    "\n",
    "SaveToFile = True \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Last changes\n",
    "------------\n",
    "Bagging\n",
    "No FavorTrueClass\n",
    "Train/Test split 0.05\n",
    "\n",
    "27NOV19-1\n",
    "-----------------------\n",
    "-----------------------\n",
    "-8.61052\n",
    "-----------------------\n",
    "-----------------------\n",
    "\n",
    "#### Exploratory Analysis\n",
    "Analysis = False\n",
    "\n",
    "#### Column Removal\n",
    "Remove_Cols_with_many_bad_data = True\n",
    "NaN_Zero_Threshold = 0.8\n",
    "\n",
    "#### Outliers\n",
    "RemoveOutliers = False    #Using IQR\n",
    "Times_IQR = 1.5           #Normal factor (1.5). Kills minority class if class included!!\n",
    "\n",
    "## Outliers by class\n",
    "RemoveOutliers_PositiveClass = False\n",
    "RemoveOutliers_NegativeClass = False  #It removes >90% of the class\n",
    "\n",
    "#### NaN and Zero replacement\n",
    "NaN_Zero_Replacement = True\n",
    "NaN_Zero_Replacement_Mode = 'perClass' #general or perClass\n",
    "NaN_Zero_Replacement_Operation = 'median' #median or mean\n",
    "NaN_Zero_Replacement_Sort = True\n",
    "\n",
    "#### Data Projections\n",
    "ProjectBins = True\n",
    "ProjectBin_Operation = \"mean\"  #sum or mean\n",
    "RemoveSubBins = True\n",
    "\n",
    "#### Rounding values\n",
    "Rounding = True     #Does not change the results and makes the process faster\n",
    "RoudingDecimals = 2\n",
    "\n",
    "#### Feature Selection\n",
    "RunCorrelationAnalysis = False   #Using Pearson Correlation\n",
    "Corr_FeatureSelection = 1   #0, 1, 2, 3, 4\n",
    "\n",
    "#### Resampling\n",
    "Upsampling = True                #Previous to Bagging\n",
    "UpsamplingAproach = \"SMOTE\"    #ADASYN/SMOTE\n",
    "\n",
    "#### Random Forest Parameters\n",
    "# Train-Test split\n",
    "EnableSplitting = True    #If False, no RF score and CM can be calculated\n",
    "_test_size = 0.05\n",
    "# RF\n",
    "_max_depth = 5\n",
    "_n_estimators = 100\n",
    "_bootstrap = True\n",
    "_class_weight ='balanced'\n",
    "_SEED = 1\n",
    "_n_jobs = -1\n",
    "\n",
    "#### Bagging\n",
    "Bagging = True\n",
    "# BC\n",
    "_n_bootstraps = 3\n",
    "_n_estimators = 10\n",
    "_max_samples = 1.0\n",
    "_max_features = 1.0\n",
    "_bootstrap = True\n",
    "_bootstrap_features = False\n",
    "_bootstrap = True\n",
    "_bootstrap_features = False\n",
    "_oob_score = False\n",
    "_warm_start = False\n",
    "_n_jobs = None\n",
    "_random_state = None\n",
    "_verbose = 0\n",
    "\n",
    "#### Favor True Class (after prediction)\n",
    "FavorTrueClass = False\n",
    "FavorThreshold = 0.45    #All False predictions between [0.5,FavorThreshold) are switched to True\n",
    "\n",
    "SaveToFile = True \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Last changes\n",
    "------------\n",
    "Bagging\n",
    "FavorTrueClass\n",
    "No Train/Test split\n",
    "\n",
    "27NOV19-2\n",
    "-----------------------\n",
    "-----------------------\n",
    "-8.30526\n",
    "-----------------------\n",
    "-----------------------\n",
    "\n",
    "\n",
    "#### Exploratory Analysis\n",
    "Analysis = False\n",
    "\n",
    "#### Column Removal\n",
    "Remove_Cols_with_many_bad_data = True\n",
    "NaN_Zero_Threshold = 0.8\n",
    "\n",
    "#### Outliers\n",
    "RemoveOutliers = False    #Using IQR\n",
    "Times_IQR = 1.5           #Normal factor (1.5). Kills minority class if class included!!\n",
    "\n",
    "## Outliers by class\n",
    "RemoveOutliers_PositiveClass = False\n",
    "RemoveOutliers_NegativeClass = False  #It removes >90% of the class\n",
    "\n",
    "#### NaN and Zero replacement\n",
    "NaN_Zero_Replacement = True\n",
    "NaN_Zero_Replacement_Mode = 'perClass' #general or perClass\n",
    "NaN_Zero_Replacement_Operation = 'median' #median or mean\n",
    "NaN_Zero_Replacement_Sort = True\n",
    "\n",
    "#### Data Projections\n",
    "ProjectBins = True\n",
    "ProjectBin_Operation = \"mean\"  #sum or mean\n",
    "RemoveSubBins = True\n",
    "\n",
    "#### Rounding values\n",
    "Rounding = True     #Does not change the results and makes the process faster\n",
    "RoudingDecimals = 2\n",
    "\n",
    "#### Feature Selection\n",
    "RunCorrelationAnalysis = False   #Using Pearson Correlation\n",
    "Corr_FeatureSelection = 1   #0, 1, 2, 3, 4\n",
    "\n",
    "#### Resampling\n",
    "Upsampling = True                #Previous to Bagging\n",
    "UpsamplingAproach = \"SMOTE\"    #ADASYN/SMOTE\n",
    "\n",
    "#### Random Forest Parameters\n",
    "# Train-Test split\n",
    "EnableSplitting = False    #If False, no RF score and CM can be calculated\n",
    "_test_size = 0.05\n",
    "# RF\n",
    "_max_depth = 5\n",
    "_n_estimators = 100\n",
    "_bootstrap = True\n",
    "_class_weight ='balanced'\n",
    "_SEED = 1\n",
    "_n_jobs = -1\n",
    "\n",
    "#### Bagging\n",
    "Bagging = True\n",
    "# BC\n",
    "_n_bootstraps = 3\n",
    "_n_estimators = 10\n",
    "_max_samples = 1.0\n",
    "_max_features = 1.0\n",
    "_bootstrap = True\n",
    "_bootstrap_features = False\n",
    "_bootstrap = True\n",
    "_bootstrap_features = False\n",
    "_oob_score = False\n",
    "_warm_start = False\n",
    "_n_jobs = None\n",
    "_random_state = None\n",
    "_verbose = 0\n",
    "\n",
    "#### Favor True Class (after prediction)\n",
    "FavorTrueClass = True\n",
    "FavorThreshold = 0.45    #All False predictions between [0.5,FavorThreshold) are switched to True\n",
    "\n",
    "SaveToFile = True \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Last changes\n",
    "------------\n",
    "Upsampling ADASYN\n",
    "Bagging RF\n",
    "No FavorTrueClass\n",
    "Train/Test split 0.10\n",
    "\n",
    "28NOV19-1\n",
    "-----------------------\n",
    "-----------------------\n",
    "-8.04210\n",
    "-----------------------\n",
    "-----------------------\n",
    "\n",
    "\n",
    "#### Exploratory Analysis\n",
    "Analysis = False\n",
    "\n",
    "#### Column Removal\n",
    "Remove_Cols_with_many_bad_data = True\n",
    "NaN_Zero_Threshold = 0.8\n",
    "\n",
    "#### Outliers\n",
    "RemoveOutliers = False    #Using IQR\n",
    "Times_IQR = 1.5           #Normal factor (1.5). Kills minority class if class included!!\n",
    "\n",
    "## Outliers by class\n",
    "RemoveOutliers_PositiveClass = False\n",
    "RemoveOutliers_NegativeClass = False  #It removes >90% of the class\n",
    "\n",
    "#### NaN and Zero replacement\n",
    "NaN_Zero_Replacement = True\n",
    "NaN_Zero_Replacement_Mode = 'perClass' #general or perClass\n",
    "NaN_Zero_Replacement_Operation = 'median' #median or mean\n",
    "NaN_Zero_Replacement_Sort = True\n",
    "\n",
    "#### Data Projections\n",
    "ProjectBins = True\n",
    "ProjectBin_Operation = \"mean\"  #sum or mean\n",
    "RemoveSubBins = True\n",
    "\n",
    "#### Rounding values\n",
    "Rounding = True     #Does not change the results and makes the process faster\n",
    "RoudingDecimals = 2\n",
    "\n",
    "#### Feature Selection\n",
    "RunCorrelationAnalysis = False   #Using Pearson Correlation\n",
    "Corr_FeatureSelection = 1   #0, 1, 2, 3, 4\n",
    "\n",
    "#### Resampling\n",
    "Upsampling = True                #Previous to Bagging\n",
    "UpsamplingAproach = \"ADASYN\"    #ADASYN/SMOTE\n",
    "\n",
    "#### Random Forest Parameters\n",
    "# Train-Test split\n",
    "EnableSplitting = True    #If False, no RF score and CM can be calculated\n",
    "_test_size = 0.1\n",
    "# RF\n",
    "_max_depth = 5        #None (default)\n",
    "_n_estimators = 100\n",
    "_bootstrap = True\n",
    "_class_weight ='balanced'\n",
    "_SEED = 1\n",
    "_n_jobs = -1\n",
    "\n",
    "#### Bagging\n",
    "Bagging = True\n",
    "# BC\n",
    "_n_bootstraps = 3\n",
    "_n_estimators = 10\n",
    "_max_samples = 1.0\n",
    "_max_features = 1.0\n",
    "_bootstrap = True\n",
    "_bootstrap_features = False\n",
    "_bootstrap = True\n",
    "_bootstrap_features = False\n",
    "_oob_score = False\n",
    "_warm_start = False\n",
    "_n_jobs = None\n",
    "_random_state = None\n",
    "_verbose = 0\n",
    "\n",
    "#### Favor True Class (after prediction)\n",
    "FavorTrueClass = False\n",
    "FavorThreshold = 0.45    #All False predictions between [0.5,FavorThreshold) are switched to True\n",
    "\n",
    "SaveToFile = True \n",
    "\n",
    "\n",
    "\n",
    "Last changes\n",
    "------------\n",
    "Upsampling ADASYN\n",
    "Bagging to _n_bootstraps=5?\n",
    "No FavorTrueClass\n",
    "Train/Test split 0.10\n",
    "\n",
    "28NOV19-2\n",
    "-----------------------\n",
    "-----------------------\n",
    "-8.58947\n",
    "-----------------------\n",
    "-----------------------\n",
    "#### Exploratory Analysis\n",
    "Analysis = False\n",
    "\n",
    "#### Column Removal\n",
    "Remove_Cols_with_many_bad_data = True\n",
    "NaN_Zero_Threshold = 0.8\n",
    "\n",
    "#### Outliers\n",
    "RemoveOutliers = False    #Using IQR\n",
    "Times_IQR = 1.5           #Normal factor (1.5). Kills minority class if class included!!\n",
    "\n",
    "## Outliers by class\n",
    "RemoveOutliers_PositiveClass = False\n",
    "RemoveOutliers_NegativeClass = False  #It removes >90% of the class\n",
    "\n",
    "#### NaN and Zero replacement\n",
    "NaN_Zero_Replacement = True\n",
    "NaN_Zero_Replacement_Mode = 'perClass' #general or perClass\n",
    "NaN_Zero_Replacement_Operation = 'median' #median or mean\n",
    "NaN_Zero_Replacement_Sort = True\n",
    "\n",
    "#### Data Projections\n",
    "ProjectBins = True\n",
    "ProjectBin_Operation = \"mean\"  #sum or mean\n",
    "RemoveSubBins = True\n",
    "\n",
    "#### Rounding values\n",
    "Rounding = True     #Does not change the results and makes the process faster\n",
    "RoudingDecimals = 2\n",
    "\n",
    "#### Feature Selection\n",
    "RunCorrelationAnalysis = False   #Using Pearson Correlation\n",
    "Corr_FeatureSelection = 1   #0, 1, 2, 3, 4\n",
    "\n",
    "#### Resampling\n",
    "Upsampling = True                #Previous to Bagging\n",
    "UpsamplingAproach = \"ADASYN\"    #ADASYN/SMOTE\n",
    "\n",
    "#### Random Forest Parameters\n",
    "# Train-Test split\n",
    "EnableSplitting = True    #If False, no RF score and CM can be calculated\n",
    "_test_size = 0.05\n",
    "# RF\n",
    "_max_depth = 5        #None (default)\n",
    "_n_estimators = 100\n",
    "_bootstrap = True\n",
    "_class_weight ='balanced'\n",
    "_SEED = 1\n",
    "_n_jobs = -1\n",
    "\n",
    "#### Bagging\n",
    "Bagging = True\n",
    "# BC\n",
    "_n_bootstraps = 5\n",
    "_n_estimators = 10\n",
    "_max_samples = 1.0\n",
    "_max_features = 1.0\n",
    "_bootstrap = True\n",
    "_bootstrap_features = False\n",
    "_bootstrap = True\n",
    "_bootstrap_features = False\n",
    "_oob_score = False\n",
    "_warm_start = False\n",
    "_n_jobs = None\n",
    "_random_state = None\n",
    "_verbose = 0\n",
    "\n",
    "#### Favor True Class (after prediction)\n",
    "FavorTrueClass = False\n",
    "FavorThreshold = 0.4    #All False predictions between [0.5,FavorThreshold) are switched to True\n",
    "\n",
    "SaveToFile = True \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Last changes\n",
    "------------\n",
    "No Bin Projections\n",
    "No Feature selection (0)\n",
    "Upsampling ADASYN\n",
    "Bagging to _n_bootstraps=5?\n",
    "FavorTrueClass\n",
    "Train/Test split 0.10\n",
    "\n",
    "29NOV19-1\n",
    "-----------------------\n",
    "-----------------------\n",
    "-27.73684\n",
    "-----------------------\n",
    "-----------------------\n",
    "\n",
    "#### Exploratory Analysis\n",
    "Analysis = False\n",
    "\n",
    "#### Column Removal\n",
    "Remove_Cols_with_many_bad_data = True\n",
    "NaN_Zero_Threshold = 0.8\n",
    "\n",
    "#### Outliers\n",
    "RemoveOutliers = False    #Using IQR\n",
    "Times_IQR = 1.5           #Normal factor (1.5). Kills minority class if class included!!\n",
    "\n",
    "## Outliers by class\n",
    "RemoveOutliers_PositiveClass = False\n",
    "RemoveOutliers_NegativeClass = False  #It removes >90% of the class\n",
    "\n",
    "#### NaN and Zero replacement\n",
    "NaN_Zero_Replacement = True\n",
    "NaN_Zero_Replacement_Mode = 'perClass' #general or perClass\n",
    "NaN_Zero_Replacement_Operation = 'median' #median or mean\n",
    "NaN_Zero_Replacement_Sort = True\n",
    "\n",
    "#### Data Projections\n",
    "ProjectBins = False\n",
    "ProjectBin_Operation = \"mean\"  #sum or mean\n",
    "RemoveSubBins = True\n",
    "\n",
    "#### Rounding values\n",
    "Rounding = True     #Does not change the results and makes the process faster\n",
    "RoudingDecimals = 2\n",
    "\n",
    "#### Feature Selection\n",
    "RunCorrelationAnalysis = False   #Using Pearson Correlation\n",
    "Corr_FeatureSelection = 0   #0, 1, 2, 3, 4\n",
    "\n",
    "#### Resampling\n",
    "Upsampling = True                #Previous to Bagging\n",
    "UpsamplingAproach = \"ADASYN\"    #ADASYN/SMOTE\n",
    "\n",
    "#### Random Forest Parameters\n",
    "# Train-Test split\n",
    "EnableSplitting = True    #If False, no RF score and CM can be calculated\n",
    "_test_size = 0.10\n",
    "# RF\n",
    "_max_depth = 5        #None (default)\n",
    "_n_estimators = 100\n",
    "_bootstrap = True\n",
    "_class_weight ='balanced'\n",
    "_SEED = 1\n",
    "_n_jobs = -1\n",
    "\n",
    "#### Bagging\n",
    "Bagging = True\n",
    "# BC\n",
    "_n_bootstraps = 3\n",
    "_n_estimators = 10\n",
    "_max_samples = 1.0\n",
    "_max_features = 1.0\n",
    "_bootstrap = True\n",
    "_bootstrap_features = False\n",
    "_bootstrap = True\n",
    "_bootstrap_features = False\n",
    "_oob_score = False\n",
    "_warm_start = False\n",
    "_n_jobs = None\n",
    "_random_state = None\n",
    "_verbose = 0\n",
    "\n",
    "#### Favor True Class (after prediction)\n",
    "FavorTrueClass = True\n",
    "FavorThreshold = 0.4    #All False predictions between [0.5,FavorThreshold) are switched to True\n",
    "\n",
    "SaveToFile = True \n",
    "\n",
    "\n",
    "\n",
    "Last changes\n",
    "------------\n",
    "No PerClass NaN replacement\n",
    "No resampling\n",
    "Feature Sel 0\n",
    "RF\n",
    "Bagging\n",
    "Train/Test split 0.10\n",
    "\n",
    "5DIC19-1\n",
    "-----------------------\n",
    "-----------------------\n",
    "-8.83157\n",
    "-----------------------\n",
    "-----------------------\n",
    "#### Exploratory Analysis\n",
    "Analysis = False\n",
    "\n",
    "#### Column Removal\n",
    "Remove_Cols_with_many_bad_data = True\n",
    "NaN_Zero_Threshold = 0.8\n",
    "\n",
    "#### Outliers\n",
    "RemoveOutliers = False    #Using IQR\n",
    "Times_IQR = 1.5           #Normal factor (1.5). Kills minority class if class included!!\n",
    "\n",
    "## Outliers by class\n",
    "RemoveOutliers_PositiveClass = False\n",
    "RemoveOutliers_NegativeClass = False  #It removes >90% of the class\n",
    "\n",
    "#### NaN and Zero replacement\n",
    "NaN_Zero_Replacement = True\n",
    "NaN_Zero_Replacement_Mode = 'general' #general or perClass\n",
    "NaN_Zero_Replacement_Operation = 'median' #median or mean\n",
    "NaN_Zero_Replacement_Sort = True\n",
    "\n",
    "#### Data Projections\n",
    "ProjectBins = True\n",
    "ProjectBin_Operation = \"mean\"  #sum or mean\n",
    "RemoveSubBins = True\n",
    "\n",
    "#### Rounding values\n",
    "Rounding = False     #Does not change the results and makes the process faster\n",
    "RoudingDecimals = 2\n",
    "\n",
    "#### Feature Selection\n",
    "RunCorrelationAnalysis = False   #Using Pearson Correlation\n",
    "Corr_FeatureSelection = 0   #0, 1, 2, 3, 4\n",
    "\n",
    "#### Resampling\n",
    "Upsampling = False                #Previous to Bagging\n",
    "UpsamplingAproach = \"ADASYN\"    #ADASYN/SMOTE\n",
    "\n",
    "#### Train-Test split\n",
    "EnableSplitting = True    #If False, no RF score and CM can be calculated\n",
    "_test_size = 0.1\n",
    "\n",
    "#### GridSearch\n",
    "GridSearch = True\n",
    "_cv = 5\n",
    "_verbose = 3\n",
    "## RF\n",
    "ParamGrid_RF = {'max_depth': [2,4,5,6], 'n_estimators':[100,150], \\\n",
    "                'class_weight':[{0:1,1:2},{1:2,0:1},{0:1,1:35},{1:35,0:1},'balanced'], \\\n",
    "                'verbose':[1], 'bootstrap': [True]};    # 'class_weight':[{0:1,1:35},{1:35,0:1}]\n",
    "## SVM\n",
    "SVM_Kernels = ['rbf','linear']    #['linear', 'rbf','sigmoid','poly']\n",
    "SVM_Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "SVM_gammas = [0.001, 0.01, 0.1, 1, 'scale']\n",
    "ParamGrid_SVM = {'kernel': SVM_Kernels, 'C': SVM_Cs, 'gamma': SVM_gammas, 'verbose':[2]}\n",
    "\n",
    "#### Model to Use\n",
    "Multimode = False   # Not implemented\n",
    "ModelToUse = 'RF'  # RF,SVM\n",
    "\n",
    "#### Random Forest Parameters (ONLY WHEN GRIDSEARCH False)\n",
    "_max_depth = 5        #None (default)\n",
    "_n_estimators = 100\n",
    "_bootstrap = True\n",
    "_class_weight ='balanced'\n",
    "_SEED = 1\n",
    "_n_jobs = -1\n",
    "\n",
    "#### Support Vector Machine (ONLY WHEN GRIDSEARCH False)\n",
    "_C=10.0\n",
    "_kernel='sigmoid'       #'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'\n",
    "_degree=3               #3(default)\n",
    "_gamma='scale'\n",
    "_coef0=0.0\n",
    "_shrinking=True\n",
    "_probability=True\n",
    "_tol=0.001\n",
    "_cache_size=200\n",
    "_class_weight=None\n",
    "_verbose=True\n",
    "_max_iter=-1\n",
    "_decision_function_shape='ovr'\n",
    "_random_state=None\n",
    "\n",
    "#### Bagging\n",
    "Bagging = True\n",
    "# BC\n",
    "_n_bootstraps = 3\n",
    "_n_estimators = 10\n",
    "_max_samples = 1.0\n",
    "_max_features = 1.0\n",
    "_bootstrap = True\n",
    "_bootstrap_features = False\n",
    "_bootstrap = True\n",
    "_bootstrap_features = False\n",
    "_oob_score = False\n",
    "_warm_start = False\n",
    "_n_jobs = 4\n",
    "_random_state = None\n",
    "_verbose = 3\n",
    "\n",
    "#### Favor True Class (after prediction), not needed if SearchGreed (with scorer) True\n",
    "FavorTrueClass = False\n",
    "FavorThreshold = 0.45    #All False predictions between [0.5,FavorThreshold) are switched to True\n",
    "\n",
    "SaveToFile = True\n",
    "FileName = \"prediction_results_v6_MAC.csv\"\n",
    "\n",
    "#### Use existing model\n",
    "UseExistingModel = False\n",
    "modelFileName = \"model_v6_MAC.joblib\"\n",
    "if (UseExistingModel == True):\n",
    "    print(\"Using model from disk!!!!!!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
